{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Emb_SimCLR_Practice.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b4cb745811f0430da4d76ab9197e214d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_aec2e5efd6c74f798afa7e3044e08bc0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c92b41f801634977b87cd227d95a58ec","IPY_MODEL_aadeee250cbe40bbbf0be654408db90f"]}},"aec2e5efd6c74f798afa7e3044e08bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c92b41f801634977b87cd227d95a58ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c5918e2aabee4d27a84926bcea5ce113","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa7b1233bb89443eb03fa4efbc002567"}},"aadeee250cbe40bbbf0be654408db90f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_22f50250a6b24717b67d4db5d4af792c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:20&lt;00:00, 83567737.35it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b8586e211d4401c8685252065b96ed5"}},"c5918e2aabee4d27a84926bcea5ce113":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aa7b1233bb89443eb03fa4efbc002567":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22f50250a6b24717b67d4db5d4af792c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8b8586e211d4401c8685252065b96ed5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"pIbUUOphvNRR","executionInfo":{"status":"ok","timestamp":1601259415440,"user_tz":-540,"elapsed":5200,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"5ec96fbd-1f4f-4fe2-ed69-464439d7800e","colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["  pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n","  Cloning https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to /tmp/pip-req-build-wyqs7os8\n","  Running command git clone -q https://github.com/ildoonet/pytorch-gradual-warmup-lr.git /tmp/pip-req-build-wyqs7os8\n","Building wheels for collected packages: warmup-scheduler\n","  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3.2-cp36-none-any.whl size=3881 sha256=f9584d647069a615ee821513de39a3de786732286c807a2b7783e98514e1d214\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-75mg8wjj/wheels/b7/24/83/d30234cc013cff538805b14df916e79091f7cf9ee2c5bf3a64\n","Successfully built warmup-scheduler\n","Installing collected packages: warmup-scheduler\n","Successfully installed warmup-scheduler-0.3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DYtKgry8uqb3","executionInfo":{"status":"ok","timestamp":1601259419060,"user_tz":-540,"elapsed":7840,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision.datasets as datasets\n","\n","import numpy as np\n","\n","import os\n","\n","import time"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZ4WM8_Guqb6"},"source":["### Step 1. Construct a CNN model\n","\n","#### Implementation 1-1. Design SimCLRHead class\n","\n","#### Implementation 1-2. Design SimCLRNet class"]},{"cell_type":"code","metadata":{"id":"DvfdvwkQuqb6","executionInfo":{"status":"ok","timestamp":1601259419431,"user_tz":-540,"elapsed":6807,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["import math\n","from torchvision.models.resnet import conv3x3\n","\n","class BasicBlock(nn.Module):\n","    def __init__(self, inplanes, planes, norm_layer, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.downsample = downsample\n","        self.stride = stride\n","        \n","        self.bn1 = norm_layer(inplanes)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        \n","        self.bn2 = norm_layer(planes)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","\n","    def forward(self, x):\n","        residual = x \n","        residual = self.bn1(residual)\n","        residual = self.relu1(residual)\n","        residual = self.conv1(residual)\n","\n","        residual = self.bn2(residual)\n","        residual = self.relu2(residual)\n","        residual = self.conv2(residual)\n","\n","        if self.downsample is not None:\n","            x = self.downsample(x)\n","        return x + residual\n","\n","class Downsample(nn.Module):\n","    def __init__(self, nIn, nOut, stride):\n","        super(Downsample, self).__init__()\n","        self.avg = nn.AvgPool2d(stride)\n","        assert nOut % nIn == 0\n","        self.expand_ratio = nOut // nIn\n","\n","    def forward(self, x):\n","        x = self.avg(x)\n","        return torch.cat([x] + [x.mul(0)] * (self.expand_ratio - 1), 1)\n","\n","class ResNetCifar(nn.Module):\n","    def __init__(self, depth, width=1, classes=10, channels=3, norm_layer=nn.BatchNorm2d):\n","        assert (depth - 2) % 6 == 0         # depth is 6N+2\n","        self.N = (depth - 2) // 6\n","        super(ResNetCifar, self).__init__()\n","\n","        # Following the Wide ResNet convention, we fix the very first convolution\n","        self.conv1 = nn.Conv2d(channels, 16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.inplanes = 16\n","        self.layer1 = self._make_layer(norm_layer, 16 * width)\n","        self.layer2 = self._make_layer(norm_layer, 32 * width, stride=2)\n","        self.layer3 = self._make_layer(norm_layer, 64 * width, stride=2)\n","        self.bn = norm_layer(64 * width)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.avgpool = nn.AvgPool2d(8)\n","\n","        # Initialization\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                \n","    def _make_layer(self, norm_layer, planes, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes:\n","            downsample = Downsample(self.inplanes, planes, stride)\n","        layers = [BasicBlock(self.inplanes, planes, norm_layer, stride, downsample)]\n","        self.inplanes = planes\n","        for i in range(self.N - 1):\n","            layers.append(BasicBlock(self.inplanes, planes, norm_layer))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        return x\n","\n","    \n","class Normalize(nn.Module):\n","\n","    def __init__(self, power=2):\n","        super(Normalize, self).__init__()\n","        self.power = power\n","\n","    def forward(self, x):\n","        norm = x.pow(self.power).sum(1, keepdim=True).pow(1. / self.power)\n","        out = x.div(norm)\n","        return out\n","    \n","\n","class SimCLRHead(nn.Module):\n","    def __init__(self, width, emb_dim):\n","        super(SimCLRHead, self).__init__()\n","        \n","        ### IMPLEMENTATION 1-1 ###\n","        ### 1. Linear layer (64 * width -> 64 * width)\n","        ### 2. ReLU\n","        ### 3. Linear layer (64 * width -> emb_dim)\n","        ### 4. Normalization layer (Normalize module above)\n","        self.fc1 = nn.Linear(64 * width, 64 * width)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.fc2 = nn.Linear(64 * width, emb_dim)\n","        self.norm = Normalize()\n","        ### IMPLEMENTATION ENDS HERE ###\n","        \n","    def forward(self, x):\n","        \n","        ### IMPLEMENTATION 1-1 ###\n","        ### Design a proper forward function\n","        \n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.norm(x)\n","\n","        ### IMPLEMENTATION ENDS HERE ###\n","        return x\n","    \n","\n","class SimCLRNet(nn.Module):\n","    def __init__(self, depth, width=1, num_classes=10, emb_dim=32):\n","        super(SimCLRNet, self).__init__()\n","        \n","        self.num_classes = num_classes\n","        \n","        self.feat = ResNetCifar(depth=depth, width=width, classes=num_classes)\n","        \n","        ### IMPLEMENTATION 1-2 ###\n","        ### 1. A projection head (SimCLRHead module above)\n","        self.head = SimCLRHead(width, emb_dim)\n","        \n","        ### 2. A linear classifier (64 * width -> num_classes)\n","        self.classifier = nn.Linear(64 * width, num_classes)\n","        \n","        ### 3. Normalization layer for conv feature normalization (Normalize module above)\n","        self.norm = Normalize()\n","        \n","        ### IMPLEMENTATION ENDS HERE ###\n","    \n","    def forward(self, x, norm_feat=False):\n","        \n","        ### IMPLEMENTATION 1-2 ###\n","        ### Your module must return\n","        ### 1. Conv feature (feat) - when norm_feat is true, apply L2 normalization\n","        ### 2. Projected embedding (emb)\n","        ### 3. Logit vector by the linear classifier (logit)\n","        \n","        feat = self.feat(x)\n","        if norm_feat :\n","          feat = self.norm(feat)\n","        \n","        emb = self.head(feat)\n","        logit = self.classifier(feat)\n","\n","        ### IMPLEMENTATION ENDS HERE ###\n","        return feat, emb, logit"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OvxUSFm-uqb9"},"source":["### Step 2. Prepare datasets & data augmentations\n","\n","For contrastaive learning, a set of random augmentation functions is first defined.\n","\n","Then, the set is applied twice to each image, which is implemented as provided DuplicatedCompose module\n","\n","#### Implementation 2-1. Design a train transform (train_transform)\n","\n","Follow the instruction inside the train_transform\n","\n","https://pytorch.org/docs/stable/torchvision/transforms.html\n","\n","Refer to the torchvision.transforms documentation"]},{"cell_type":"code","metadata":{"id":"S53vsB4Iuqb9","executionInfo":{"status":"ok","timestamp":1601259419433,"user_tz":-540,"elapsed":2711,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["class DuplicatedCompose(object):\n","    def __init__(self, transforms):\n","        self.transforms = transforms\n","\n","    def __call__(self, img):\n","        img1 = img.copy()\n","        img2 = img.copy()\n","        for t in self.transforms:\n","            img1 = t(img1)\n","            img2 = t(img2)\n","        return img1, img2"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ex83YAnMuqcA","executionInfo":{"status":"ok","timestamp":1601259420139,"user_tz":-540,"elapsed":2149,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["import cv2\n","cv2.setNumThreads(0)\n","\n","class GaussianBlur(object):\n","    # Implements Gaussian blur as described in the SimCLR paper\n","    def __init__(self, kernel_size, min=0.1, max=2.0):\n","        self.min = min\n","        self.max = max\n","        # kernel size is set to be 10% of the image height/width\n","        self.kernel_size = kernel_size\n","        \n","        if self.kernel_size % 2 == 0:\n","            self.kernel_size += 1\n","\n","    def __call__(self, sample):\n","        sample = np.array(sample)\n","\n","        # blur the image with a 50% chance\n","        prob = np.random.random_sample()\n","\n","        if prob < 0.5:\n","            sigma = (self.max - self.min) * np.random.random_sample() + self.min\n","            sample = cv2.GaussianBlur(sample, (self.kernel_size, self.kernel_size), sigma)\n","\n","        return sample"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xHmdyuguqcC","executionInfo":{"status":"ok","timestamp":1601259420535,"user_tz":-540,"elapsed":799,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["import torchvision.transforms as transforms\n","\n","img_size = (32, 32)\n","\n","color_jitter = transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n","\n","train_transform = DuplicatedCompose([\n","    ### IMPLEMENTATION 2-1 ###\n","    ### 1. Random resized crop w/ final size of (32, 32)\n","    ### 2. Random horizontal flip w/ p=0.5\n","    ### 3. Randomly apply the pre-defined color jittering w/ p=0.8\n","    ### 4. Random gray scale w/ p=0.2\n","    ### 5. Gaussian blur w/ kernel size of 1/10 of the image width or height (32)\n","    transforms.RandomResizedCrop(img_size),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    color_jitter,\n","    transforms.RandomGrayscale(p=0.2),\n","    GaussianBlur(img_size[0]//10),\n","    \n","    ### IMPLEMENTATION ENDS HERE ###\n","    transforms.ToTensor(),\n","])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zo9Xj3KruqcE","executionInfo":{"status":"ok","timestamp":1601259427156,"user_tz":-540,"elapsed":5875,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"c381e2ef-ee49-4cbb-beb7-76ad024a2926","colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["b4cb745811f0430da4d76ab9197e214d","aec2e5efd6c74f798afa7e3044e08bc0","c92b41f801634977b87cd227d95a58ec","aadeee250cbe40bbbf0be654408db90f","c5918e2aabee4d27a84926bcea5ce113","aa7b1233bb89443eb03fa4efbc002567","22f50250a6b24717b67d4db5d4af792c","8b8586e211d4401c8685252065b96ed5"]}},"source":["from torch.utils.data import DataLoader\n","\n","train_dataset = datasets.CIFAR10(root='.',\n","                                 train=True,\n","                                 download=True,\n","                                 transform=train_transform\n","                                )\n","\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=256,\n","                          num_workers=4,\n","                          shuffle=True,\n","                          drop_last=True\n","                         )"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4cb745811f0430da4d76ab9197e214d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./cifar-10-python.tar.gz to .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6xwkINzBuqcH"},"source":["### Step 3. Implement InfoNCE loss"]},{"cell_type":"code","metadata":{"id":"MUjxzqf6uqcI","executionInfo":{"status":"ok","timestamp":1601259427158,"user_tz":-540,"elapsed":4084,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["class NTXentLoss(torch.nn.Module):\n","\n","    def __init__(self, batch_size, temperature, use_cosine_similarity):\n","        super(NTXentLoss, self).__init__()\n","        self.batch_size = batch_size\n","        self.temperature = temperature\n","        self.softmax = torch.nn.Softmax(dim=-1)\n","        self.mask_samples_from_same_repr = self._get_correlated_mask().type(torch.bool)\n","        self.similarity_function = self._get_similarity_function(use_cosine_similarity)\n","        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n","\n","    def _get_similarity_function(self, use_cosine_similarity):\n","        if use_cosine_similarity:\n","            self._cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n","            return self._cosine_simililarity\n","        else:\n","            return self._dot_simililarity\n","\n","    def _get_correlated_mask(self):\n","        diag = np.eye(2 * self.batch_size)\n","        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n","        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n","        mask = torch.from_numpy((diag + l1 + l2))\n","        mask = (1 - mask).type(torch.bool)\n","        return mask.cuda()\n","\n","    @staticmethod\n","    def _dot_simililarity(x, y):\n","        v = torch.tensordot(x.unsqueeze(1), y.T.unsqueeze(0), dims=2)\n","        # x shape: (N, 1, C)\n","        # y shape: (1, C, 2N)\n","        # v shape: (N, 2N)\n","        return v\n","\n","    def _cosine_simililarity(self, x, y):\n","        # x shape: (N, 1, C)\n","        # y shape: (1, 2N, C)\n","        # v shape: (N, 2N)\n","        v = self._cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n","        return v\n","\n","    def forward(self, zis, zjs):\n","        representations = torch.cat([zjs, zis], dim=0)\n","\n","        similarity_matrix = self.similarity_function(representations, representations)\n","\n","        # filter out the scores from the positive samples\n","        l_pos = torch.diag(similarity_matrix, self.batch_size)\n","        r_pos = torch.diag(similarity_matrix, -self.batch_size)\n","        positives = torch.cat([l_pos, r_pos]).view(2 * self.batch_size, 1)\n","\n","        negatives = similarity_matrix[self.mask_samples_from_same_repr].view(2 * self.batch_size, -1)\n","\n","        logits = torch.cat((positives, negatives), dim=1)\n","        logits = logits / self.temperature\n","\n","        labels = torch.zeros(2 * self.batch_size).cuda().long()\n","        loss = self.criterion(logits, labels)\n","\n","        return loss / (2 * self.batch_size)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-SGunpIuqcK"},"source":["### Step 4. Run pre-training step\n","\n","#### Implementation 4-1. Complete a basic SimCLR training loop\n","\n","https://github.com/ildoonet/pytorch-gradual-warmup-lr\n","\n","The linear warmup scheduler implementation is from a github in the link above\n","\n","https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","\n","Refer to this documentation to use lr schedulers integrated in PyTorch"]},{"cell_type":"code","metadata":{"id":"UlL2Yl5AuqcL","executionInfo":{"status":"ok","timestamp":1601259427159,"user_tz":-540,"elapsed":2111,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["from torch.optim.optimizer import Optimizer, required\n","\n","class SGD_with_lars(Optimizer):\n","    r\"\"\"Implements stochastic gradient descent (optionally with momentum).\n","    \"\"\"\n","\n","    def __init__(self, params, lr=required, momentum=0, weight_decay=0, trust_coef=1.): # need to add trust coef\n","        if lr is not required and lr < 0.0:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if momentum < 0.0:\n","            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n","        if weight_decay < 0.0:\n","            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n","        if trust_coef < 0.0:\n","            raise ValueError(\"Invalid trust_coef value: {}\".format(trust_coef))\n","\n","        defaults = dict(lr=lr, momentum=momentum, weight_decay=weight_decay, trust_coef=trust_coef)\n","\n","        super(SGD_with_lars, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(SGD_with_lars, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","            weight_decay = group['weight_decay']\n","            momentum = group['momentum']\n","            trust_coef = group['trust_coef']\n","            global_lr = group['lr']\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                d_p = p.grad.data\n","\n","                p_norm = torch.norm(p.data, p=2)\n","                d_p_norm = torch.norm(d_p, p=2).add_(momentum, p_norm)\n","                lr = torch.div(p_norm, d_p_norm).mul_(trust_coef)\n","\n","                lr.mul_(global_lr)\n","\n","                if weight_decay != 0:\n","                    d_p.add_(weight_decay, p.data)\n","\n","                d_p.mul_(lr)\n","\n","                if momentum != 0:\n","                    param_state = self.state[p]\n","                    if 'momentum_buffer' not in param_state:\n","                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n","                    else:\n","                        buf = param_state['momentum_buffer']\n","                        buf.mul_(momentum).add_(d_p)\n","                    d_p = buf\n","\n","                p.data.add_(-1, d_p)\n","\n","        return loss"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fjc3wkcuqcN","executionInfo":{"status":"ok","timestamp":1601259427936,"user_tz":-540,"elapsed":761,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["def train(net, loader):\n","    \n","    batch_size=256\n","    temperature=0.07\n","\n","    loss_fn = NTXentLoss(batch_size=batch_size, temperature=temperature, use_cosine_similarity=True)\n","    \n","    ### IMPLEMENTATION 4-2 ###\n","    ### 1. Use SGD_with_lars with\n","    ### lr = 0.1 * batch_size / 256\n","    ### momentum = 0.9\n","    ### weight_decay = 1e-6\n","    optimizer = SGD_with_lars(net.parameters(), lr = 0.1 * batch_size / 256, momentum=0.9, weight_decay=1e-6)\n","    \n","    from warmup_scheduler import GradualWarmupScheduler\n","    ### 2. Use GradualWarmupScheduler with\n","    ### multiplier = 1\n","    ### total_epoch = 1/10 of total epochs\n","    ### after_scheduler = optim.lr_scheduler.CosineAnnealingLR\n","    scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=20, \n","                                       after_scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=180))\n","    \n","    train_start = time.time()\n","    \n","    loss_hist = []\n","\n","    for epoch in range(1, 200 + 1):\n","        \n","        train_loss = 0\n","        net.train()\n","        \n","        epoch_start = time.time()\n","        for idx, (data, target) in enumerate(loader):\n","            optimizer.zero_grad()\n","            \n","            ### 3. data variable contains two augmented images\n","            ### -1. send them to your GPU by calling .cuda()\n","            ### -2. forward each of them to net\n","            ### -3. compute the InfoNCE loss\n","            \n","            # target : labels.\n","\n","            zi, zj = data\n","            \n","            feat_i, emb_i, logit_i = net(zi.cuda())\n","            feat_j, emb_j, logit_j = net(zj.cuda())\n","            loss = loss_fn(emb_i, emb_j)\n","\n","            ### IMPLEMENTATION ENDS HERE ###\n","            \n","            train_loss += loss.item()\n","            \n","            loss.backward()\n","            optimizer.step()\n","            \n","        train_loss /= (idx + 1)\n","        loss_hist.append(train_loss) # added by junwon\n","        scheduler.step()\n","        \n","        epoch_time = time.time() - epoch_start\n","        print(\"Epoch\\t\", epoch, \n","              \"\\tLoss\\t\", train_loss, \n","              \"\\tTime\\t\", epoch_time,\n","             )\n","        \n","    elapsed_train_time = time.time() - train_start\n","    print('Finished training. Train time was:', elapsed_train_time)\n","\n","    return loss_hist\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"w2Bqj--ZuqcR","executionInfo":{"status":"ok","timestamp":1601259439257,"user_tz":-540,"elapsed":10109,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"f8265d9e-930d-4bf3-9e70-793386e8d16b","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["GPU_NUM = '0'\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_NUM\n","\n","net = SimCLRNet(26, 1, 10, 32)\n","\n","net.cuda()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SimCLRNet(\n","  (feat): ResNetCifar(\n","    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (1): BasicBlock(\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (2): BasicBlock(\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (3): BasicBlock(\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (downsample): Downsample(\n","          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","        )\n","        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (1): BasicBlock(\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (2): BasicBlock(\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (3): BasicBlock(\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (downsample): Downsample(\n","          (avg): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","        )\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (1): BasicBlock(\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (2): BasicBlock(\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (3): BasicBlock(\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace=True)\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n","  )\n","  (head): SimCLRHead(\n","    (fc1): Linear(in_features=64, out_features=64, bias=True)\n","    (relu): ReLU(inplace=True)\n","    (fc2): Linear(in_features=64, out_features=32, bias=True)\n","    (norm): Normalize()\n","  )\n","  (classifier): Linear(in_features=64, out_features=10, bias=True)\n","  (norm): Normalize()\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"43yf5jCluqcT","executionInfo":{"status":"ok","timestamp":1600953363220,"user_tz":-540,"elapsed":13052651,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"70b4b6cc-5c5e-4723-fe3f-fb35082e96c9","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#net.zero_grad()\n","loss_list = train(net, train_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch\t 1 \tLoss\t 6.267516270661965 \tTime\t 68.65935754776001\n","Epoch\t 2 \tLoss\t 5.997548533708621 \tTime\t 69.4774341583252\n","Epoch\t 3 \tLoss\t 5.726462474236121 \tTime\t 69.28733396530151\n","Epoch\t 4 \tLoss\t 5.385201908991887 \tTime\t 69.1840991973877\n","Epoch\t 5 \tLoss\t 5.067203159821339 \tTime\t 69.04848051071167\n","Epoch\t 6 \tLoss\t 4.6063751465235 \tTime\t 69.27956533432007\n","Epoch\t 7 \tLoss\t 4.163073110580444 \tTime\t 69.10657048225403\n","Epoch\t 8 \tLoss\t 3.8278773857997015 \tTime\t 69.57406044006348\n","Epoch\t 9 \tLoss\t 3.618078660964966 \tTime\t 69.37399625778198\n","Epoch\t 10 \tLoss\t 3.4667221289414627 \tTime\t 69.22460794448853\n","Epoch\t 11 \tLoss\t 3.326366952749399 \tTime\t 69.36655616760254\n","Epoch\t 12 \tLoss\t 3.212576044522799 \tTime\t 68.8926649093628\n","Epoch\t 13 \tLoss\t 3.1059215570107486 \tTime\t 69.45085096359253\n","Epoch\t 14 \tLoss\t 3.0056425815973524 \tTime\t 69.58503246307373\n","Epoch\t 15 \tLoss\t 2.9502402220016872 \tTime\t 69.60094261169434\n","Epoch\t 16 \tLoss\t 2.8980539407485573 \tTime\t 69.69247913360596\n","Epoch\t 17 \tLoss\t 2.8292446454366047 \tTime\t 69.91272926330566\n","Epoch\t 18 \tLoss\t 2.796525651980669 \tTime\t 69.46855235099792\n","Epoch\t 19 \tLoss\t 2.751286535996657 \tTime\t 69.60183310508728\n","Epoch\t 20 \tLoss\t 2.725570794863579 \tTime\t 69.23428440093994\n","Epoch\t 21 \tLoss\t 2.68677745843545 \tTime\t 69.87360668182373\n","Epoch\t 22 \tLoss\t 2.6289502498431085 \tTime\t 69.46336817741394\n","Epoch\t 23 \tLoss\t 2.565778276247856 \tTime\t 69.51942682266235\n","Epoch\t 24 \tLoss\t 2.5523773254492346 \tTime\t 68.56583619117737\n","Epoch\t 25 \tLoss\t 2.5162836417173726 \tTime\t 68.56498456001282\n","Epoch\t 26 \tLoss\t 2.4719427059858274 \tTime\t 68.42393064498901\n","Epoch\t 27 \tLoss\t 2.440567861459194 \tTime\t 68.57524490356445\n","Epoch\t 28 \tLoss\t 2.4243976103953826 \tTime\t 67.85034894943237\n","Epoch\t 29 \tLoss\t 2.413613294943785 \tTime\t 68.07151699066162\n","Epoch\t 30 \tLoss\t 2.3794657731667543 \tTime\t 67.70706510543823\n","Epoch\t 31 \tLoss\t 2.3304465990800125 \tTime\t 67.68454360961914\n","Epoch\t 32 \tLoss\t 2.328510089409657 \tTime\t 67.68454313278198\n","Epoch\t 33 \tLoss\t 2.3045998671115973 \tTime\t 67.70062136650085\n","Epoch\t 34 \tLoss\t 2.3009905790671326 \tTime\t 65.9900324344635\n","Epoch\t 35 \tLoss\t 2.2688993539565647 \tTime\t 66.22203993797302\n","Epoch\t 36 \tLoss\t 2.2497884664780052 \tTime\t 65.22188997268677\n","Epoch\t 37 \tLoss\t 2.2232157413776106 \tTime\t 64.85269021987915\n","Epoch\t 38 \tLoss\t 2.226406777822054 \tTime\t 64.0560052394867\n","Epoch\t 39 \tLoss\t 2.2295812050501507 \tTime\t 64.37019276618958\n","Epoch\t 40 \tLoss\t 2.21929702881055 \tTime\t 63.95195126533508\n","Epoch\t 41 \tLoss\t 2.180020068242 \tTime\t 64.59342861175537\n","Epoch\t 42 \tLoss\t 2.160928560525943 \tTime\t 63.999021768569946\n","Epoch\t 43 \tLoss\t 2.1956578480891693 \tTime\t 64.270911693573\n","Epoch\t 44 \tLoss\t 2.1445052813260985 \tTime\t 64.21836233139038\n","Epoch\t 45 \tLoss\t 2.132634694759662 \tTime\t 64.14633202552795\n","Epoch\t 46 \tLoss\t 2.135455678670834 \tTime\t 64.37652349472046\n","Epoch\t 47 \tLoss\t 2.1240479744397676 \tTime\t 63.687742710113525\n","Epoch\t 48 \tLoss\t 2.0787297719564193 \tTime\t 63.95740842819214\n","Epoch\t 49 \tLoss\t 2.1051991059229924 \tTime\t 64.48335433006287\n","Epoch\t 50 \tLoss\t 2.0988356437438576 \tTime\t 63.944589138031006\n","Epoch\t 51 \tLoss\t 2.0975300550460814 \tTime\t 63.56045651435852\n","Epoch\t 52 \tLoss\t 2.0864494030292215 \tTime\t 63.19982552528381\n","Epoch\t 53 \tLoss\t 2.0579177122849686 \tTime\t 63.13495445251465\n","Epoch\t 54 \tLoss\t 2.0632026782402626 \tTime\t 63.20989727973938\n","Epoch\t 55 \tLoss\t 2.0569946533594377 \tTime\t 63.129993200302124\n","Epoch\t 56 \tLoss\t 2.040649994214376 \tTime\t 63.33056855201721\n","Epoch\t 57 \tLoss\t 2.041300230148511 \tTime\t 63.07570481300354\n","Epoch\t 58 \tLoss\t 2.033439413095132 \tTime\t 63.639230251312256\n","Epoch\t 59 \tLoss\t 2.013191468287737 \tTime\t 63.89214277267456\n","Epoch\t 60 \tLoss\t 2.020325320194929 \tTime\t 63.60252404212952\n","Epoch\t 61 \tLoss\t 2.0273418237001466 \tTime\t 63.32847881317139\n","Epoch\t 62 \tLoss\t 1.9968146959940591 \tTime\t 63.407280921936035\n","Epoch\t 63 \tLoss\t 2.018937667210897 \tTime\t 63.60285401344299\n","Epoch\t 64 \tLoss\t 2.00002297376975 \tTime\t 63.400835037231445\n","Epoch\t 65 \tLoss\t 1.9655543339558137 \tTime\t 63.673710107803345\n","Epoch\t 66 \tLoss\t 2.0207853048275677 \tTime\t 64.17776226997375\n","Epoch\t 67 \tLoss\t 1.978113309542338 \tTime\t 63.82818102836609\n","Epoch\t 68 \tLoss\t 1.9487998033181215 \tTime\t 63.906532764434814\n","Epoch\t 69 \tLoss\t 1.945285551975935 \tTime\t 63.87592911720276\n","Epoch\t 70 \tLoss\t 1.9744266436650202 \tTime\t 63.786917209625244\n","Epoch\t 71 \tLoss\t 1.9542911425614968 \tTime\t 63.49198579788208\n","Epoch\t 72 \tLoss\t 1.9325912976876283 \tTime\t 63.555681228637695\n","Epoch\t 73 \tLoss\t 1.9276562910813553 \tTime\t 63.57647895812988\n","Epoch\t 74 \tLoss\t 1.9361189304253994 \tTime\t 63.422266721725464\n","Epoch\t 75 \tLoss\t 1.9350018507395035 \tTime\t 63.535187005996704\n","Epoch\t 76 \tLoss\t 1.926993179321289 \tTime\t 62.564146995544434\n","Epoch\t 77 \tLoss\t 1.9250775862962772 \tTime\t 63.04930877685547\n","Epoch\t 78 \tLoss\t 1.9121704645645925 \tTime\t 63.07352638244629\n","Epoch\t 79 \tLoss\t 1.8979068737763625 \tTime\t 63.042041301727295\n","Epoch\t 80 \tLoss\t 1.8915438193541307 \tTime\t 62.6722686290741\n","Epoch\t 81 \tLoss\t 1.8916537180925026 \tTime\t 63.21482062339783\n","Epoch\t 82 \tLoss\t 1.9038298612985856 \tTime\t 63.78955006599426\n","Epoch\t 83 \tLoss\t 1.8805216654753074 \tTime\t 63.44261360168457\n","Epoch\t 84 \tLoss\t 1.8818345858500554 \tTime\t 63.472145318984985\n","Epoch\t 85 \tLoss\t 1.893834277911064 \tTime\t 62.656704902648926\n","Epoch\t 86 \tLoss\t 1.8679261170900785 \tTime\t 62.974589586257935\n","Epoch\t 87 \tLoss\t 1.8642448761524297 \tTime\t 62.813273191452026\n","Epoch\t 88 \tLoss\t 1.8449247977672478 \tTime\t 63.055755615234375\n","Epoch\t 89 \tLoss\t 1.8696678986916175 \tTime\t 63.302762031555176\n","Epoch\t 90 \tLoss\t 1.8722039497815646 \tTime\t 62.85462260246277\n","Epoch\t 91 \tLoss\t 1.870667578623845 \tTime\t 62.75846743583679\n","Epoch\t 92 \tLoss\t 1.8474222091528085 \tTime\t 63.194554805755615\n","Epoch\t 93 \tLoss\t 1.8648451676735511 \tTime\t 62.94294333457947\n","Epoch\t 94 \tLoss\t 1.8446526399025551 \tTime\t 62.87138080596924\n","Epoch\t 95 \tLoss\t 1.8276663988064497 \tTime\t 63.0919828414917\n","Epoch\t 96 \tLoss\t 1.8224965651830038 \tTime\t 63.08124852180481\n","Epoch\t 97 \tLoss\t 1.8225131157117012 \tTime\t 63.06569290161133\n","Epoch\t 98 \tLoss\t 1.8259998278740124 \tTime\t 63.35394859313965\n","Epoch\t 99 \tLoss\t 1.831270324266874 \tTime\t 63.41454291343689\n","Epoch\t 100 \tLoss\t 1.833235372029818 \tTime\t 62.99313187599182\n","Epoch\t 101 \tLoss\t 1.817083610021151 \tTime\t 62.80047941207886\n","Epoch\t 102 \tLoss\t 1.8051621987269475 \tTime\t 62.8501501083374\n","Epoch\t 103 \tLoss\t 1.8123325830850845 \tTime\t 63.097904920578\n","Epoch\t 104 \tLoss\t 1.7852651388217242 \tTime\t 63.0553183555603\n","Epoch\t 105 \tLoss\t 1.8084005435307822 \tTime\t 62.94760346412659\n","Epoch\t 106 \tLoss\t 1.8041324670498187 \tTime\t 63.25816869735718\n","Epoch\t 107 \tLoss\t 1.7820193205124293 \tTime\t 62.923250675201416\n","Epoch\t 108 \tLoss\t 1.7962806524374546 \tTime\t 62.94171738624573\n","Epoch\t 109 \tLoss\t 1.7930817304513393 \tTime\t 62.812955379486084\n","Epoch\t 110 \tLoss\t 1.789792967453981 \tTime\t 62.79203796386719\n","Epoch\t 111 \tLoss\t 1.7812223055423835 \tTime\t 62.60554313659668\n","Epoch\t 112 \tLoss\t 1.785346525754684 \tTime\t 63.17959928512573\n","Epoch\t 113 \tLoss\t 1.7885493657527827 \tTime\t 63.33392405509949\n","Epoch\t 114 \tLoss\t 1.7671677020879892 \tTime\t 62.74914860725403\n","Epoch\t 115 \tLoss\t 1.7685645977656046 \tTime\t 63.25654315948486\n","Epoch\t 116 \tLoss\t 1.7716081185218615 \tTime\t 62.876837730407715\n","Epoch\t 117 \tLoss\t 1.7829843594477728 \tTime\t 63.14761471748352\n","Epoch\t 118 \tLoss\t 1.772922008465498 \tTime\t 62.828460693359375\n","Epoch\t 119 \tLoss\t 1.7659885754952065 \tTime\t 63.11888647079468\n","Epoch\t 120 \tLoss\t 1.7448960218674097 \tTime\t 63.22929286956787\n","Epoch\t 121 \tLoss\t 1.7520486501547006 \tTime\t 63.6432888507843\n","Epoch\t 122 \tLoss\t 1.7521573433509239 \tTime\t 62.95422625541687\n","Epoch\t 123 \tLoss\t 1.7678827206293741 \tTime\t 63.3798565864563\n","Epoch\t 124 \tLoss\t 1.7502376458583735 \tTime\t 62.8237099647522\n","Epoch\t 125 \tLoss\t 1.769895480840634 \tTime\t 62.9195613861084\n","Epoch\t 126 \tLoss\t 1.756000240643819 \tTime\t 62.95954418182373\n","Epoch\t 127 \tLoss\t 1.7506872965739324 \tTime\t 62.67074799537659\n","Epoch\t 128 \tLoss\t 1.745745114179758 \tTime\t 63.118263483047485\n","Epoch\t 129 \tLoss\t 1.7377324495560085 \tTime\t 63.108617067337036\n","Epoch\t 130 \tLoss\t 1.7158134686641204 \tTime\t 63.02924919128418\n","Epoch\t 131 \tLoss\t 1.7412236030285175 \tTime\t 62.89516854286194\n","Epoch\t 132 \tLoss\t 1.7306649568753365 \tTime\t 62.679909229278564\n","Epoch\t 133 \tLoss\t 1.7245748746089447 \tTime\t 62.66066098213196\n","Epoch\t 134 \tLoss\t 1.7289566480196439 \tTime\t 63.32841229438782\n","Epoch\t 135 \tLoss\t 1.7108234833448361 \tTime\t 62.491352558135986\n","Epoch\t 136 \tLoss\t 1.6991298583837655 \tTime\t 62.3332724571228\n","Epoch\t 137 \tLoss\t 1.7115736839098807 \tTime\t 62.74306297302246\n","Epoch\t 138 \tLoss\t 1.7007082712955963 \tTime\t 62.762959718704224\n","Epoch\t 139 \tLoss\t 1.7187429745992024 \tTime\t 62.61979103088379\n","Epoch\t 140 \tLoss\t 1.6926693610655956 \tTime\t 62.504223346710205\n","Epoch\t 141 \tLoss\t 1.7033146136846298 \tTime\t 62.608073472976685\n","Epoch\t 142 \tLoss\t 1.7205791528408343 \tTime\t 62.628968715667725\n","Epoch\t 143 \tLoss\t 1.6938049933849237 \tTime\t 62.75688982009888\n","Epoch\t 144 \tLoss\t 1.7151904136706622 \tTime\t 63.039963483810425\n","Epoch\t 145 \tLoss\t 1.6962251809927134 \tTime\t 63.067909717559814\n","Epoch\t 146 \tLoss\t 1.6823487367385472 \tTime\t 62.384145736694336\n","Epoch\t 147 \tLoss\t 1.6853399460132306 \tTime\t 62.321884632110596\n","Epoch\t 148 \tLoss\t 1.6768621634214351 \tTime\t 62.94698643684387\n","Epoch\t 149 \tLoss\t 1.6715527577277942 \tTime\t 62.54809641838074\n","Epoch\t 150 \tLoss\t 1.665389627065414 \tTime\t 62.6585054397583\n","Epoch\t 151 \tLoss\t 1.6830049331371602 \tTime\t 62.95280051231384\n","Epoch\t 152 \tLoss\t 1.6835978721960998 \tTime\t 62.745948791503906\n","Epoch\t 153 \tLoss\t 1.67967787644802 \tTime\t 62.68786954879761\n","Epoch\t 154 \tLoss\t 1.6763857138462557 \tTime\t 62.95465064048767\n","Epoch\t 155 \tLoss\t 1.6782261481651892 \tTime\t 62.714362382888794\n","Epoch\t 156 \tLoss\t 1.6617795449036818 \tTime\t 62.96763586997986\n","Epoch\t 157 \tLoss\t 1.675019753896273 \tTime\t 62.9510543346405\n","Epoch\t 158 \tLoss\t 1.675074587112818 \tTime\t 65.35823965072632\n","Epoch\t 159 \tLoss\t 1.6546062561181876 \tTime\t 71.55635094642639\n","Epoch\t 160 \tLoss\t 1.6746668840065981 \tTime\t 71.21927261352539\n","Epoch\t 161 \tLoss\t 1.6435573663467016 \tTime\t 69.76940560340881\n","Epoch\t 162 \tLoss\t 1.6557708746347672 \tTime\t 69.46242380142212\n","Epoch\t 163 \tLoss\t 1.6678790911650045 \tTime\t 69.35124659538269\n","Epoch\t 164 \tLoss\t 1.664384509355594 \tTime\t 71.1125271320343\n","Epoch\t 165 \tLoss\t 1.6600723688419048 \tTime\t 71.94162893295288\n","Epoch\t 166 \tLoss\t 1.661243896606641 \tTime\t 72.01282262802124\n","Epoch\t 167 \tLoss\t 1.6629147285070174 \tTime\t 72.33958768844604\n","Epoch\t 168 \tLoss\t 1.6620125477130596 \tTime\t 72.95786356925964\n","Epoch\t 169 \tLoss\t 1.6602887862767928 \tTime\t 73.96707892417908\n","Epoch\t 170 \tLoss\t 1.6492626385811047 \tTime\t 74.312002658844\n","Epoch\t 171 \tLoss\t 1.6598077217737834 \tTime\t 74.04334545135498\n","Epoch\t 172 \tLoss\t 1.6313616501979338 \tTime\t 73.81621289253235\n","Epoch\t 173 \tLoss\t 1.6453075335575984 \tTime\t 73.28137230873108\n","Epoch\t 174 \tLoss\t 1.6391288347733326 \tTime\t 71.95601725578308\n","Epoch\t 175 \tLoss\t 1.6526925508792585 \tTime\t 70.92093181610107\n","Epoch\t 176 \tLoss\t 1.6408355028201371 \tTime\t 70.17202544212341\n","Epoch\t 177 \tLoss\t 1.6741687591259296 \tTime\t 69.64730167388916\n","Epoch\t 178 \tLoss\t 1.6493007904443986 \tTime\t 69.17150163650513\n","Epoch\t 179 \tLoss\t 1.6307186945890768 \tTime\t 67.66972494125366\n","Epoch\t 180 \tLoss\t 1.6318966621007676 \tTime\t 67.56845283508301\n","Epoch\t 181 \tLoss\t 1.6460150443590604 \tTime\t 66.0144100189209\n","Epoch\t 182 \tLoss\t 1.6342561336664052 \tTime\t 65.29189372062683\n","Epoch\t 183 \tLoss\t 1.6374236284158168 \tTime\t 65.38262867927551\n","Epoch\t 184 \tLoss\t 1.6324674893648197 \tTime\t 65.18134713172913\n","Epoch\t 185 \tLoss\t 1.6391727582002298 \tTime\t 65.1057243347168\n","Epoch\t 186 \tLoss\t 1.6311474506671613 \tTime\t 64.95918345451355\n","Epoch\t 187 \tLoss\t 1.6350793679555258 \tTime\t 64.83811283111572\n","Epoch\t 188 \tLoss\t 1.6467056940763425 \tTime\t 64.92646360397339\n","Epoch\t 189 \tLoss\t 1.6347985512171037 \tTime\t 65.87502717971802\n","Epoch\t 190 \tLoss\t 1.6369034186387674 \tTime\t 65.06599950790405\n","Epoch\t 191 \tLoss\t 1.6355789410762298 \tTime\t 64.79733896255493\n","Epoch\t 192 \tLoss\t 1.6241045731764574 \tTime\t 64.38663864135742\n","Epoch\t 193 \tLoss\t 1.6254989746289374 \tTime\t 63.669490575790405\n","Epoch\t 194 \tLoss\t 1.6319795125570054 \tTime\t 63.83303713798523\n","Epoch\t 195 \tLoss\t 1.6416837533315023 \tTime\t 64.1012270450592\n","Epoch\t 196 \tLoss\t 1.625650544044299 \tTime\t 64.25086784362793\n","Epoch\t 197 \tLoss\t 1.6344465396343133 \tTime\t 64.62059736251831\n","Epoch\t 198 \tLoss\t 1.6315676242877275 \tTime\t 64.30861186981201\n","Epoch\t 199 \tLoss\t 1.6486536013774382 \tTime\t 64.37908816337585\n","Epoch\t 200 \tLoss\t 1.6273717764096383 \tTime\t 64.58815407752991\n","Finished training. Train time was: 13051.887996673584\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j8TTC-0U-Xkt","executionInfo":{"status":"ok","timestamp":1601259439259,"user_tz":-540,"elapsed":7041,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["import matplotlib.pyplot as plt\n","\n","def plot_loss(loss_hist, xlabel='Iteration number', ylabel='Loss value') :\n","  plt.plot(loss_hist)\n","  plt.xlabel(xlabel)\n","  plt.ylabel(ylabel)\n","  plt.show()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVo5Msnl--6B","executionInfo":{"status":"ok","timestamp":1600953528378,"user_tz":-540,"elapsed":696,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"5998825a-5a5a-4f56-a8b5-632444f16936","colab":{"base_uri":"https://localhost:8080/","height":279}},"source":["plot_loss(loss_list)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"8ufE49N8BcxA","executionInfo":{"status":"ok","timestamp":1601259439260,"user_tz":-540,"elapsed":5017,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["def save_model(model, model_save_name = 'SIMCLR.pt' ) :\n","  # save ckpt in google drive.\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","  path = F\"/content/gdrive/My Drive/{model_save_name}\" \n","  torch.save(model.state_dict(), path)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztekTngYVO20","executionInfo":{"status":"ok","timestamp":1601259439261,"user_tz":-540,"elapsed":3921,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["def load_model(model, path='SIMCLR.pt') :\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","  checkpoints_folder =  F\"/content/gdrive/My Drive/{path}\" \n","  state_dict = torch.load(checkpoints_folder)\n","  model.load_state_dict(state_dict)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"5CPurz9SuqcV","executionInfo":{"status":"ok","timestamp":1601091880440,"user_tz":-540,"elapsed":18886,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"0932d603-ad0d-4ec4-9f4a-07c0c469e9e7","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["save_model(net, \"simclr_new.pt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u6q9K4_lgIJB","executionInfo":{"status":"ok","timestamp":1601259454702,"user_tz":-540,"elapsed":18006,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"985d1681-30f9-46d1-f116-49a30964a8fc","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["load_model(net, \"simclr_new.pt\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QDATNL_YuUIP"},"source":["## Linear Evaluation Protocol\n","\n","- train Linear classifier with freezed extractor f"]},{"cell_type":"code","metadata":{"id":"ocucN1fyuTZU","executionInfo":{"status":"ok","timestamp":1601259457400,"user_tz":-540,"elapsed":853,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["def train_classifier(net, loader):\n","    \n","    batch_size=256\n","    temperature=0.07\n","\n","    loss_fn = torch.nn.CrossEntropyLoss()\n","\n","    # Freezing\n","    net.feat.requires_grad = False\n","    net.head.requires_grad = False\n","    net.norm.requires_grad = False\n","\n","   # net.feat.train(False)\n","  \n","    optimizer = torch.optim.Adam(net.classifier.parameters(), lr=1e-3)\n","    \n","    train_start = time.time()\n","    \n","    loss_hist = []\n","    min_loss = 10000\n","\n","    for epoch in range(1, 10 + 1):\n","        \n","        train_loss = 0\n","        #net.feat.train(False)\n","        #net.classifier.train(True) \n","        net.train()\n","        epoch_start = time.time()\n","\n","        for idx, (data, target) in enumerate(loader):\n","            optimizer.zero_grad()\n","            \n","            feat, emb, logit = net(data.cuda())\n","            \n","            loss = loss_fn(logit, target.cuda())\n","          \n","            train_loss += loss.item()\n","            \n","            loss.backward()\n","            optimizer.step()\n","            \n","        train_loss /= (idx + 1)\n","        loss_hist.append(train_loss) # added by junwon\n","        if train_loss < min_loss :\n","          min_loss = train_loss\n","          save_model(net, \"classifier\")\n","       \n","        epoch_time = time.time() - epoch_start\n","        print(\"Epoch\\t\", epoch, \n","              \"\\tLoss\\t\", train_loss, \n","              \"\\tTime\\t\", epoch_time,\n","             )\n","        \n","    elapsed_train_time = time.time() - train_start\n","    print('Finished training. Train time was:', elapsed_train_time)\n","\n","    return loss_hist\n","\n","def test_classifier(net, loader) :\n","  \n","  net.eval()\n","  \n","  correct = 0\n","  total = 0\n","  \n","  with torch.no_grad() :\n","    for idx, (data, target) in enumerate(loader):\n","      \n","      feat, emb, logit = net(data.cuda())\n","      #loss = loss_fn(logit, target.cuda())\n","      \n","      _, class_i = torch.max(logit.data, 1)\n","\n","      correct += (class_i == target.cuda()).sum().item()  \n","      total += target.size(0)\n","\n","    accuracy = correct / total\n","    print('Accuracy : %d %%' % (100 * accuracy))\n","  \n","  return accuracy\n","  \n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTV1vdlDYlWt","executionInfo":{"status":"ok","timestamp":1601259461188,"user_tz":-540,"elapsed":2276,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"91653ff8-333a-4a7e-8b54-85a46b1a7567","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from torch.utils.data import DataLoader\n","\n","linear_dataset = datasets.CIFAR10(root='.',\n","                                 train=True,\n","                                 download=True,\n","                                 transform=transforms.ToTensor()\n","                                )\n","\n","linear_loader = DataLoader(linear_dataset,\n","                          batch_size=256,\n","                          num_workers=4,\n","                          shuffle=True,\n","                          drop_last=True\n","                         )\n","\n","test_dataset = datasets.CIFAR10(root='.',\n","                                 train=False,\n","                                 download=True,\n","                                 transform=transforms.ToTensor()\n","                                )\n","\n","test_loader = DataLoader(test_dataset,\n","                          batch_size=256,\n","                          num_workers=4,\n","                          shuffle=True,\n","                          drop_last=True\n","                         )"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6gBtJya5UsO1","executionInfo":{"status":"ok","timestamp":1600956080948,"user_tz":-540,"elapsed":515277,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"70fde04b-12ee-466e-f63a-e8753a69243a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["loss_list = train_classifier(net, linear_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 1 \tLoss\t 2.03468404121888 \tTime\t 17.137782096862793\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 2 \tLoss\t 1.6301073435025337 \tTime\t 17.24441909790039\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 3 \tLoss\t 1.4283286290291028 \tTime\t 17.066750288009644\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 4 \tLoss\t 1.3150144711518899 \tTime\t 17.026099681854248\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 5 \tLoss\t 1.2440750293242626 \tTime\t 17.067901849746704\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 6 \tLoss\t 1.1951002854567307 \tTime\t 17.105433702468872\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 7 \tLoss\t 1.1595835169156392 \tTime\t 17.125438451766968\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 8 \tLoss\t 1.1338184274159946 \tTime\t 17.08957076072693\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 9 \tLoss\t 1.1112631134497815 \tTime\t 17.097830295562744\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 10 \tLoss\t 1.0948643947258974 \tTime\t 17.093303203582764\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 11 \tLoss\t 1.0812407942918631 \tTime\t 17.017643213272095\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 12 \tLoss\t 1.0695079476405414 \tTime\t 17.06408953666687\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 13 \tLoss\t 1.0593032726874718 \tTime\t 17.09551215171814\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 14 \tLoss\t 1.0512505369308667 \tTime\t 17.128983736038208\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 15 \tLoss\t 1.0428527550819593 \tTime\t 17.111952304840088\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 16 \tLoss\t 1.0376738615525074 \tTime\t 17.099048852920532\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 17 \tLoss\t 1.031489634513855 \tTime\t 17.15119194984436\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 18 \tLoss\t 1.027635129292806 \tTime\t 17.12689518928528\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 19 \tLoss\t 1.022793124577938 \tTime\t 17.13813066482544\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 20 \tLoss\t 1.0190817640377925 \tTime\t 17.150291204452515\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 21 \tLoss\t 1.014194057537959 \tTime\t 17.08976435661316\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 22 \tLoss\t 1.0108654868908418 \tTime\t 17.163275003433228\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 23 \tLoss\t 1.0085886481480721 \tTime\t 17.21928095817566\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 24 \tLoss\t 1.006259562113346 \tTime\t 17.208226680755615\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 25 \tLoss\t 1.002286654863602 \tTime\t 17.335190057754517\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 26 \tLoss\t 0.9998141579138927 \tTime\t 17.245723962783813\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 27 \tLoss\t 0.9975449063839057 \tTime\t 17.2394061088562\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 28 \tLoss\t 0.9960140689825401 \tTime\t 17.307114362716675\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 29 \tLoss\t 0.9927120361572657 \tTime\t 17.32283854484558\n","Epoch\t 30 \tLoss\t 0.9929774443308512 \tTime\t 17.321990966796875\n","Finished training. Train time was: 514.6455535888672\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SNUX8YOYgnNW","executionInfo":{"status":"ok","timestamp":1600956088698,"user_tz":-540,"elapsed":2633,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"49721a9c-523b-4935-e7cb-9f3319b94b09","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["acc = test_classifier(net, test_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy : 64 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3yKmtkiya2FF"},"source":["## classifier를 Train할 때 Epoch\n","계속 Loss 낮아지지만, 이미 60%를 넘으므로. \n","Pretrain 성능을 평가하기 위해 \n","\"초기에 얼마나 트레인이 잘 되는지\" 를 평가하기 위해서 에폭을 늘리지 않음. "]},{"cell_type":"markdown","metadata":{"id":"Pek2bM80tkes"},"source":["##Train Function with Parameters.\n","\n","- save the model with lowest loss\n","- parameters : batch_size, temparture, pre-training epochs.\n","\n"]},{"cell_type":"code","metadata":{"id":"rDJ6q_OzGOxz","executionInfo":{"status":"ok","timestamp":1601259499383,"user_tz":-540,"elapsed":624,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["from torch.utils.data import DataLoader\n","\n","def make_loader(batch_size) :\n","  \n","  train_dataset = datasets.CIFAR10(root='.',\n","                                  train=True,\n","                                  download=True,\n","                                  transform=train_transform\n","                                  )\n","\n","  train_loader = DataLoader(train_dataset,\n","                            batch_size=batch_size,\n","                            num_workers=4,\n","                            shuffle=True,\n","                            drop_last=True\n","                          )\n","  \n","  linear_dataset = datasets.CIFAR10(root='.',\n","                                 train=True,\n","                                 download=True,\n","                                 transform=transforms.ToTensor()\n","                                )\n","\n","  linear_loader = DataLoader(linear_dataset,\n","                            batch_size=batch_size,\n","                            num_workers=4,\n","                            shuffle=True,\n","                            drop_last=True\n","                          )\n","\n","  test_dataset = datasets.CIFAR10(root='.',\n","                                  train=False,\n","                                  download=True,\n","                                  transform=transforms.ToTensor()\n","                                  )\n","\n","  test_loader = DataLoader(test_dataset,\n","                            batch_size=batch_size,\n","                            num_workers=4,\n","                            shuffle=True,\n","                            drop_last=True\n","                          )\n","  \n","  return train_loader, linear_loader, test_loader"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"ak1IDc6gtpqW","executionInfo":{"status":"ok","timestamp":1601259502747,"user_tz":-540,"elapsed":682,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}}},"source":["def train_param(net, loader, batch_size = 256, temperature = 0.07, n_epoch = 200):\n","    \n","\n","    loss_fn = NTXentLoss(batch_size=batch_size, temperature=temperature, use_cosine_similarity=True)\n","    \n","\n","    optimizer = SGD_with_lars(net.parameters(), lr = 0.1 * batch_size / 256, momentum=0.9, weight_decay=1e-6)\n","    \n","    from warmup_scheduler import GradualWarmupScheduler\n","    ### 2. Use GradualWarmupScheduler with\n","    ### multiplier = 1\n","    ### total_epoch = 1/10 of total epochs\n","    ### after_scheduler = optim.lr_scheduler.CosineAnnealingLR\n","    scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch= n_epoch // 10, \n","                                       after_scheduler=optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max= n_epoch - n_epoch // 10))\n","    \n","    train_start = time.time()\n","    \n","    loss_hist = []\n","\n","    x = 0\n","    import os.path\n","    checkpoint = range(0, 300, 40)\n","    for ckpt in checkpoint :\n","      if os.path.isfile(\"/content/gdrive/My Drive/simclr_{}_{}_epoch{}in300.pt\".format(batch_size, temperature, ckpt)) :\n","        load_model(net, \"simclr_{}_{}_epoch{}in{}.pt\".format(batch_size, temperature, ckpt, 300))\n","        x = ckpt\n","        print(\"loaded\", ckpt)\n","\n","    for epoch in range(1 + x, n_epoch + 1):\n","        \n","        train_loss = 0\n","        net.train()\n","        epoch_start = time.time()\n","        for idx, (data, target) in enumerate(loader):\n","            optimizer.zero_grad()\n","            \n","            ### 3. data variable contains two augmented images\n","            ### -1. send them to your GPU by calling .cuda()\n","            ### -2. forward each of them to net\n","            ### -3. compute the InfoNCE loss\n","            \n","            # target : labels.\n","\n","            zi, zj = data\n","            feat_i, emb_i, logit_i = net(zi.cuda())\n","            feat_j, emb_j, logit_j = net(zj.cuda())\n","            \n","            loss = loss_fn(emb_i, emb_j)\n","\n","            ### IMPLEMENTATION ENDS HERE ###\n","            \n","            train_loss += loss.item()\n","            \n","            loss.backward()\n","            optimizer.step()\n","            \n","        train_loss /= (idx + 1)\n","        loss_hist.append(train_loss) # added by junwon\n","        scheduler.step()\n","        \n","        epoch_time = time.time() - epoch_start\n","        print(\"Epoch\\t\", epoch, \n","              \"\\tLoss\\t\", train_loss, \n","              \"\\tTime\\t\", epoch_time,\n","             )\n","        if epoch % 40 == 0 :\n","          save_model(net, \"simclr_{}_{}_epoch{}in{}.pt\".format(batch_size, temperature, epoch, n_epoch))\n","        \n","    elapsed_train_time = time.time() - train_start\n","    print('Finished training. Train time was:', elapsed_train_time)\n","\n","    return loss_hist"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPPyQM8Dig6a","executionInfo":{"status":"ok","timestamp":1601076165712,"user_tz":-540,"elapsed":2562,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"81d2d873-6d33-4f6b-e22d-e05594648130","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["load_model(net, \"classifier\")\n","acc = test_classifier(net, testl)\n","save_model(net, \"simclr_batch_{}.pt\".format(64))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Accuracy : 66 %\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cVW2dg4wcplr","executionInfo":{"status":"error","timestamp":1601076890204,"user_tz":-540,"elapsed":79923,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"62d67639-ea50-401b-d574-f180532b9c03","colab":{"base_uri":"https://localhost:8080/","height":460}},"source":["batch_size_list = [128, 512, 1024]\n","temperature_list = [0.01, 0.05, 0.1, 0.5, 1.0]\n","n_epoch_list = [300, 400]\n","\n","batch_loss =[]\n","temperature_loss =[]\n","epoch_loss =[]\n","\n","batch_acc =[]\n","temperature_acc =[]\n","epoch_acc =[]\n","\n","# batch_size test\n","\n","for bs in batch_size_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(bs)\n","  loss = train_param(net, tl, batch_size=bs)\n","  batch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifer(net, testl)\n","  batch_acc.append((bs, acc))\n","  save_model(net, \"simclr_batch_{}.pt\".format(bs))\n","\"\"\"\n","for t in temperature_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(256)\n","  train_param(net, tl, temperature=t)\n","  temperature_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifer(net, testl)\n","  temperature_acc.append((t, acc))\n","  save_model(net, \"simclr_tmp_{}.pt\".format(t))\n","\"\"\"\n","for n in n_epoch_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(256)\n","  loss = train_param(net, tl, n_epoch=n)\n","  epoch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifer(net, testl)\n","  epoch_acc.append((n, acc))\n","  save_model(net, \"simclr_epoch_{}.pt\".format(n))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch\t 1 \tLoss\t 5.663587763370612 \tTime\t 68.78809022903442\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-58ec35860b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-3cd7075f5e06>\u001b[0m in \u001b[0;36mtrain_param\u001b[0;34m(net, loader, batch_size, temperature, n_epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdigest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWELCOME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"KytgQGwvj8X-","outputId":"de46ff1e-c058-41f4-f248-7aaa9d9717b3","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batch_size_list = [128, 512, 1024]\n","temperature_list = [0.01, 0.05, 0.1, 0.5, 1.0]\n","n_epoch_list = [300, 400]\n","\n","batch_loss =[]\n","temperature_loss =[]\n","epoch_loss =[]\n","\n","batch_acc =[]\n","temperature_acc =[]\n","epoch_acc =[]\n","\n","# batch_size test\n","\n","for bs in batch_size_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(bs)\n","  loss = train_param(net, tl, batch_size=bs)\n","  batch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifier(net, testl)\n","  batch_acc.append((bs, acc))\n","  save_model(net, \"simclr_batch_{}.pt\".format(bs))\n","\n","for n in n_epoch_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(256)\n","  loss = train_param(net, tl, n_epoch=n)\n","  epoch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifier(net, testl)\n","  epoch_acc.append((n, acc))\n","  save_model(net, \"simclr_epoch_{}.pt\".format(n))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 80\n","Epoch\t 81 \tLoss\t 1.467620871311579 \tTime\t 74.03604197502136\n","Epoch\t 82 \tLoss\t 1.4322105331298634 \tTime\t 74.36388826370239\n","Epoch\t 83 \tLoss\t 1.3856881335759774 \tTime\t 74.10854816436768\n","Epoch\t 84 \tLoss\t 1.3918473119919117 \tTime\t 74.2172281742096\n","Epoch\t 85 \tLoss\t 1.397122600598213 \tTime\t 73.8138153553009\n","Epoch\t 86 \tLoss\t 1.3878370040502304 \tTime\t 73.92633438110352\n","Epoch\t 87 \tLoss\t 1.3976149123448591 \tTime\t 73.88465762138367\n","Epoch\t 88 \tLoss\t 1.4029193283655705 \tTime\t 74.34171271324158\n","Epoch\t 89 \tLoss\t 1.404602391597552 \tTime\t 73.97630500793457\n","Epoch\t 90 \tLoss\t 1.40906276901563 \tTime\t 73.20013427734375\n","Epoch\t 91 \tLoss\t 1.4127692193557055 \tTime\t 73.32415127754211\n","Epoch\t 92 \tLoss\t 1.4389491752172128 \tTime\t 73.53053736686707\n","Epoch\t 93 \tLoss\t 1.4445250373620253 \tTime\t 73.91549110412598\n","Epoch\t 94 \tLoss\t 1.4478514385529053 \tTime\t 73.64248943328857\n","Epoch\t 95 \tLoss\t 1.4459246976253315 \tTime\t 73.83578944206238\n","Epoch\t 96 \tLoss\t 1.4411594733213766 \tTime\t 73.76957178115845\n","Epoch\t 97 \tLoss\t 1.4713387443469121 \tTime\t 73.79276299476624\n","Epoch\t 98 \tLoss\t 1.4646333428529592 \tTime\t 73.92453050613403\n","Epoch\t 99 \tLoss\t 1.4799293475273327 \tTime\t 73.5048017501831\n","Epoch\t 100 \tLoss\t 1.4773992008123642 \tTime\t 73.37975645065308\n","Epoch\t 101 \tLoss\t 1.4874538384951077 \tTime\t 73.85653591156006\n","Epoch\t 102 \tLoss\t 1.4646449827230894 \tTime\t 73.73534893989563\n","Epoch\t 103 \tLoss\t 1.4859105330247147 \tTime\t 73.5310468673706\n","Epoch\t 104 \tLoss\t 1.4771045912534764 \tTime\t 73.95894837379456\n","Epoch\t 105 \tLoss\t 1.4795340953729093 \tTime\t 73.65819764137268\n","Epoch\t 106 \tLoss\t 1.4824002363742925 \tTime\t 73.63955903053284\n","Epoch\t 107 \tLoss\t 1.4537950239120385 \tTime\t 73.44751524925232\n","Epoch\t 108 \tLoss\t 1.4583807022143633 \tTime\t 74.5592725276947\n","Epoch\t 109 \tLoss\t 1.4728236883114545 \tTime\t 74.23765563964844\n","Epoch\t 110 \tLoss\t 1.4801456089203173 \tTime\t 73.78574800491333\n","Epoch\t 111 \tLoss\t 1.4589782528388195 \tTime\t 73.87780594825745\n","Epoch\t 112 \tLoss\t 1.4614467246410174 \tTime\t 74.24404668807983\n","Epoch\t 113 \tLoss\t 1.4389536535128569 \tTime\t 74.0022804737091\n","Epoch\t 114 \tLoss\t 1.4466732207017068 \tTime\t 74.03969287872314\n","Epoch\t 115 \tLoss\t 1.4617259219670906 \tTime\t 72.4094877243042\n","Epoch\t 116 \tLoss\t 1.4338229092267842 \tTime\t 71.81369280815125\n","Epoch\t 117 \tLoss\t 1.4212333313929728 \tTime\t 71.96690201759338\n","Epoch\t 118 \tLoss\t 1.4388219193006173 \tTime\t 72.22774147987366\n","Epoch\t 119 \tLoss\t 1.4323595161621387 \tTime\t 73.57528495788574\n","Epoch\t 120 \tLoss\t 1.4217457866057372 \tTime\t 73.77187442779541\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 121 \tLoss\t 1.4254560120594808 \tTime\t 72.93026900291443\n","Epoch\t 122 \tLoss\t 1.4373534175065847 \tTime\t 73.35538864135742\n","Epoch\t 123 \tLoss\t 1.4323359391628168 \tTime\t 71.88186764717102\n","Epoch\t 124 \tLoss\t 1.4202487129431505 \tTime\t 72.59055185317993\n","Epoch\t 125 \tLoss\t 1.422301586316182 \tTime\t 71.90649175643921\n","Epoch\t 126 \tLoss\t 1.4199129041952965 \tTime\t 70.66728782653809\n","Epoch\t 127 \tLoss\t 1.4077227814075275 \tTime\t 70.33640050888062\n","Epoch\t 128 \tLoss\t 1.39347508534407 \tTime\t 69.78823685646057\n","Epoch\t 129 \tLoss\t 1.4000343746099717 \tTime\t 69.6687798500061\n","Epoch\t 130 \tLoss\t 1.4146378854910533 \tTime\t 69.83299088478088\n","Epoch\t 131 \tLoss\t 1.414936018295777 \tTime\t 70.21638607978821\n","Epoch\t 132 \tLoss\t 1.4035833694995978 \tTime\t 70.12291622161865\n","Epoch\t 133 \tLoss\t 1.4058371279484188 \tTime\t 69.66947865486145\n","Epoch\t 134 \tLoss\t 1.4017149642491953 \tTime\t 69.69585180282593\n","Epoch\t 135 \tLoss\t 1.3928987073592651 \tTime\t 69.627610206604\n","Epoch\t 136 \tLoss\t 1.3923182539450816 \tTime\t 69.83354234695435\n","Epoch\t 137 \tLoss\t 1.3840498664440253 \tTime\t 69.50692057609558\n","Epoch\t 138 \tLoss\t 1.385158284352376 \tTime\t 69.05145859718323\n","Epoch\t 139 \tLoss\t 1.3862016161282857 \tTime\t 68.93304634094238\n","Epoch\t 140 \tLoss\t 1.3884723258324159 \tTime\t 69.23574638366699\n","Epoch\t 141 \tLoss\t 1.3792278425815778 \tTime\t 69.11372065544128\n","Epoch\t 142 \tLoss\t 1.379579773468849 \tTime\t 69.34292507171631\n","Epoch\t 143 \tLoss\t 1.3674006732610555 \tTime\t 69.1673595905304\n","Epoch\t 144 \tLoss\t 1.372118755028798 \tTime\t 69.68537664413452\n","Epoch\t 145 \tLoss\t 1.3717009084346967 \tTime\t 69.33409214019775\n","Epoch\t 146 \tLoss\t 1.3770489426759573 \tTime\t 69.06767559051514\n","Epoch\t 147 \tLoss\t 1.3738094835709302 \tTime\t 68.516184091568\n","Epoch\t 148 \tLoss\t 1.364569933597858 \tTime\t 68.72956228256226\n","Epoch\t 149 \tLoss\t 1.3592468177660917 \tTime\t 68.8677110671997\n","Epoch\t 150 \tLoss\t 1.3506346911956102 \tTime\t 68.45783185958862\n","Epoch\t 151 \tLoss\t 1.3601726165184609 \tTime\t 68.90453577041626\n","Epoch\t 152 \tLoss\t 1.3582577982009985 \tTime\t 68.70738863945007\n","Epoch\t 153 \tLoss\t 1.3531901825696995 \tTime\t 69.07528448104858\n","Epoch\t 154 \tLoss\t 1.3528217063500332 \tTime\t 68.65535688400269\n","Epoch\t 155 \tLoss\t 1.3608498620681273 \tTime\t 68.70257115364075\n","Epoch\t 156 \tLoss\t 1.3570020790283497 \tTime\t 68.67375755310059\n","Epoch\t 157 \tLoss\t 1.3404105359163039 \tTime\t 68.65468978881836\n","Epoch\t 158 \tLoss\t 1.3572270397956554 \tTime\t 69.22210931777954\n","Epoch\t 159 \tLoss\t 1.3454341584291214 \tTime\t 69.12311315536499\n","Epoch\t 160 \tLoss\t 1.332580740023882 \tTime\t 69.13072061538696\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 161 \tLoss\t 1.3470400428160643 \tTime\t 68.96761512756348\n","Epoch\t 162 \tLoss\t 1.3256147115658492 \tTime\t 68.96490049362183\n","Epoch\t 163 \tLoss\t 1.322724439547612 \tTime\t 69.07581853866577\n","Epoch\t 164 \tLoss\t 1.3147880309667344 \tTime\t 69.12022590637207\n","Epoch\t 165 \tLoss\t 1.3239974258801877 \tTime\t 69.0068793296814\n","Epoch\t 166 \tLoss\t 1.3353313939693647 \tTime\t 69.2423005104065\n","Epoch\t 167 \tLoss\t 1.3206859214183613 \tTime\t 69.19622230529785\n","Epoch\t 168 \tLoss\t 1.32980824922904 \tTime\t 69.20736718177795\n","Epoch\t 169 \tLoss\t 1.3150796605990482 \tTime\t 69.12683033943176\n","Epoch\t 170 \tLoss\t 1.3130377907019395 \tTime\t 68.99816727638245\n","Epoch\t 171 \tLoss\t 1.3421549355372404 \tTime\t 68.99987888336182\n","Epoch\t 172 \tLoss\t 1.3227286749925369 \tTime\t 68.97776937484741\n","Epoch\t 173 \tLoss\t 1.3093634649729118 \tTime\t 69.32299160957336\n","Epoch\t 174 \tLoss\t 1.3275839802546379 \tTime\t 68.99361181259155\n","Epoch\t 175 \tLoss\t 1.310425214889722 \tTime\t 68.92210555076599\n","Epoch\t 176 \tLoss\t 1.3032416271857725 \tTime\t 69.22794961929321\n","Epoch\t 177 \tLoss\t 1.3091846733521193 \tTime\t 69.27929186820984\n","Epoch\t 178 \tLoss\t 1.3004477609426548 \tTime\t 69.03552961349487\n","Epoch\t 179 \tLoss\t 1.2921853470496643 \tTime\t 69.00706434249878\n","Epoch\t 180 \tLoss\t 1.3111144431126422 \tTime\t 69.08209824562073\n","Epoch\t 181 \tLoss\t 1.2872704473825602 \tTime\t 69.15062808990479\n","Epoch\t 182 \tLoss\t 1.2933939863473942 \tTime\t 68.66103553771973\n","Epoch\t 183 \tLoss\t 1.3065688901986832 \tTime\t 73.40953397750854\n","Epoch\t 184 \tLoss\t 1.2852928132582933 \tTime\t 73.58280539512634\n","Epoch\t 185 \tLoss\t 1.2758322972517746 \tTime\t 73.17559337615967\n","Epoch\t 186 \tLoss\t 1.288685288796058 \tTime\t 69.13630104064941\n","Epoch\t 187 \tLoss\t 1.296374206053905 \tTime\t 69.07214045524597\n","Epoch\t 188 \tLoss\t 1.3090236113621638 \tTime\t 68.89098954200745\n","Epoch\t 189 \tLoss\t 1.2847209488734221 \tTime\t 69.13264536857605\n","Epoch\t 190 \tLoss\t 1.2655278068322402 \tTime\t 69.06155848503113\n","Epoch\t 191 \tLoss\t 1.2607962470788223 \tTime\t 68.66418528556824\n","Epoch\t 192 \tLoss\t 1.2825037448834151 \tTime\t 69.1622302532196\n","Epoch\t 193 \tLoss\t 1.2789150160092575 \tTime\t 68.95175671577454\n","Epoch\t 194 \tLoss\t 1.2702477692029415 \tTime\t 69.61789393424988\n","Epoch\t 195 \tLoss\t 1.2669203854524171 \tTime\t 68.92640519142151\n","Epoch\t 196 \tLoss\t 1.2679677651478694 \tTime\t 69.23318862915039\n","Epoch\t 197 \tLoss\t 1.2733810333105233 \tTime\t 69.08497524261475\n","Epoch\t 198 \tLoss\t 1.2618155855398911 \tTime\t 69.35748815536499\n","Epoch\t 199 \tLoss\t 1.2801854306306595 \tTime\t 69.23483777046204\n","Epoch\t 200 \tLoss\t 1.2714414263382936 \tTime\t 69.63243246078491\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Finished training. Train time was: 8512.188500404358\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 1 \tLoss\t 1.8316697783959217 \tTime\t 15.508225679397583\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 2 \tLoss\t 1.3640247461123345 \tTime\t 15.146164894104004\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 3 \tLoss\t 1.2073715567588805 \tTime\t 15.17440676689148\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 4 \tLoss\t 1.1329143213920103 \tTime\t 15.158110618591309\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 5 \tLoss\t 1.0877448985209832 \tTime\t 15.161277532577515\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 6 \tLoss\t 1.0589852728904823 \tTime\t 15.157585382461548\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 7 \tLoss\t 1.0369032534269187 \tTime\t 15.174489259719849\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 8 \tLoss\t 1.0228297608020978 \tTime\t 15.198696613311768\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 9 \tLoss\t 1.0091436534355849 \tTime\t 15.146648645401001\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 10 \tLoss\t 0.9993398478397957 \tTime\t 15.187487602233887\n","Finished training. Train time was: 152.02878499031067\n","Accuracy : 65 %\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch\t 1 \tLoss\t 7.1278018164880494 \tTime\t 62.55901002883911\n","Epoch\t 2 \tLoss\t 6.7136342107635185 \tTime\t 62.808714628219604\n","Epoch\t 3 \tLoss\t 6.473925148088908 \tTime\t 62.450026750564575\n","Epoch\t 4 \tLoss\t 6.168945750010383 \tTime\t 62.474342346191406\n","Epoch\t 5 \tLoss\t 5.858912418798073 \tTime\t 62.87750220298767\n","Epoch\t 6 \tLoss\t 5.463860148007107 \tTime\t 62.55917835235596\n","Epoch\t 7 \tLoss\t 5.036836339026382 \tTime\t 62.43049597740173\n","Epoch\t 8 \tLoss\t 4.783180413786898 \tTime\t 62.31223750114441\n","Epoch\t 9 \tLoss\t 4.45117484908743 \tTime\t 63.018272399902344\n","Epoch\t 10 \tLoss\t 4.2885913480188425 \tTime\t 63.4229838848114\n","Epoch\t 11 \tLoss\t 4.096152113884995 \tTime\t 63.171955585479736\n","Epoch\t 12 \tLoss\t 3.9926330723713352 \tTime\t 62.8670392036438\n","Epoch\t 13 \tLoss\t 3.8787207283924534 \tTime\t 63.3688178062439\n","Epoch\t 14 \tLoss\t 3.7515614450592354 \tTime\t 63.43156170845032\n","Epoch\t 15 \tLoss\t 3.637580478314272 \tTime\t 63.4962432384491\n","Epoch\t 16 \tLoss\t 3.54249438305491 \tTime\t 62.583754539489746\n","Epoch\t 17 \tLoss\t 3.509529271076635 \tTime\t 62.895995140075684\n","Epoch\t 18 \tLoss\t 3.4315779749880133 \tTime\t 62.97238349914551\n","Epoch\t 19 \tLoss\t 3.4258713697649767 \tTime\t 63.12336468696594\n","Epoch\t 20 \tLoss\t 3.345840562250196 \tTime\t 63.12426948547363\n","Epoch\t 21 \tLoss\t 3.33022922584691 \tTime\t 61.94918894767761\n","Epoch\t 22 \tLoss\t 3.237856948498598 \tTime\t 62.23823022842407\n","Epoch\t 23 \tLoss\t 3.1893141294263074 \tTime\t 62.30491900444031\n","Epoch\t 24 \tLoss\t 3.144611275073179 \tTime\t 62.39677333831787\n","Epoch\t 25 \tLoss\t 3.0941763809046794 \tTime\t 62.6032989025116\n","Epoch\t 26 \tLoss\t 3.0502789487543795 \tTime\t 62.29186677932739\n","Epoch\t 27 \tLoss\t 2.9849174784630845 \tTime\t 62.48262572288513\n","Epoch\t 28 \tLoss\t 2.954408390005839 \tTime\t 62.44166421890259\n","Epoch\t 29 \tLoss\t 2.9798928314877537 \tTime\t 62.31435990333557\n","Epoch\t 30 \tLoss\t 2.9137741732843145 \tTime\t 62.58849573135376\n","Epoch\t 31 \tLoss\t 2.876433755933624 \tTime\t 62.10894441604614\n","Epoch\t 32 \tLoss\t 2.848014332584499 \tTime\t 62.027527809143066\n","Epoch\t 33 \tLoss\t 2.817894741431954 \tTime\t 61.94770383834839\n","Epoch\t 34 \tLoss\t 2.826668102716662 \tTime\t 62.40858864784241\n","Epoch\t 35 \tLoss\t 2.7671898812362827 \tTime\t 62.63255739212036\n","Epoch\t 36 \tLoss\t 2.76712900584506 \tTime\t 62.182615995407104\n","Epoch\t 37 \tLoss\t 2.7493042355960178 \tTime\t 61.94101023674011\n","Epoch\t 38 \tLoss\t 2.72036745621986 \tTime\t 62.096813917160034\n","Epoch\t 39 \tLoss\t 2.7171886040992344 \tTime\t 61.79505491256714\n","Epoch\t 40 \tLoss\t 2.7192522152182983 \tTime\t 62.04936099052429\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 41 \tLoss\t 2.6825089282596233 \tTime\t 62.16067814826965\n","Epoch\t 42 \tLoss\t 2.6588713729504456 \tTime\t 62.103859424591064\n","Epoch\t 43 \tLoss\t 2.655587685476873 \tTime\t 61.928443908691406\n","Epoch\t 44 \tLoss\t 2.6420802947172186 \tTime\t 62.091522455215454\n","Epoch\t 45 \tLoss\t 2.61853052660362 \tTime\t 62.12223744392395\n","Epoch\t 46 \tLoss\t 2.5901283898304417 \tTime\t 61.85067963600159\n","Epoch\t 47 \tLoss\t 2.602181412510036 \tTime\t 61.904165506362915\n","Epoch\t 48 \tLoss\t 2.575324574696649 \tTime\t 61.88850235939026\n","Epoch\t 49 \tLoss\t 2.545782150681486 \tTime\t 62.13602685928345\n","Epoch\t 50 \tLoss\t 2.5767452839723566 \tTime\t 62.04976511001587\n","Epoch\t 51 \tLoss\t 2.552474670803424 \tTime\t 62.22776651382446\n","Epoch\t 52 \tLoss\t 2.556476983827414 \tTime\t 62.12318181991577\n","Epoch\t 53 \tLoss\t 2.5077731855136833 \tTime\t 62.06156277656555\n","Epoch\t 54 \tLoss\t 2.5156370708622884 \tTime\t 62.22513723373413\n","Epoch\t 55 \tLoss\t 2.5379017677503763 \tTime\t 62.503127574920654\n","Epoch\t 56 \tLoss\t 2.5116663863978435 \tTime\t 62.23344945907593\n","Epoch\t 57 \tLoss\t 2.488851190842304 \tTime\t 62.138761043548584\n","Epoch\t 58 \tLoss\t 2.478328812982618 \tTime\t 62.290990591049194\n","Epoch\t 59 \tLoss\t 2.4883169193857726 \tTime\t 61.84767985343933\n","Epoch\t 60 \tLoss\t 2.472288839595834 \tTime\t 62.05694365501404\n","Epoch\t 61 \tLoss\t 2.456730097839513 \tTime\t 61.937477350234985\n","Epoch\t 62 \tLoss\t 2.4722291218865777 \tTime\t 61.88125920295715\n","Epoch\t 63 \tLoss\t 2.4421268320575202 \tTime\t 62.237043380737305\n","Epoch\t 64 \tLoss\t 2.455815632318713 \tTime\t 61.78841543197632\n","Epoch\t 65 \tLoss\t 2.4515792069975864 \tTime\t 62.311574935913086\n","Epoch\t 66 \tLoss\t 2.430397503154794 \tTime\t 62.16509532928467\n","Epoch\t 67 \tLoss\t 2.4220531920796815 \tTime\t 62.46618461608887\n","Epoch\t 68 \tLoss\t 2.3872775146641683 \tTime\t 62.45889210700989\n","Epoch\t 69 \tLoss\t 2.415498391869142 \tTime\t 61.6882061958313\n","Epoch\t 70 \tLoss\t 2.3953159396181403 \tTime\t 62.34213161468506\n","Epoch\t 71 \tLoss\t 2.3939464460943163 \tTime\t 61.799612283706665\n","Epoch\t 72 \tLoss\t 2.3946964593277764 \tTime\t 62.39311122894287\n","Epoch\t 73 \tLoss\t 2.378226793918413 \tTime\t 62.09926772117615\n","Epoch\t 74 \tLoss\t 2.3854979977165303 \tTime\t 62.30005407333374\n","Epoch\t 75 \tLoss\t 2.3689558014427265 \tTime\t 62.6049587726593\n","Epoch\t 76 \tLoss\t 2.3791861951965645 \tTime\t 61.911277294158936\n","Epoch\t 77 \tLoss\t 2.3551448694209465 \tTime\t 62.28801989555359\n","Epoch\t 78 \tLoss\t 2.37357079614069 \tTime\t 62.153486013412476\n","Epoch\t 79 \tLoss\t 2.3502218403767063 \tTime\t 61.83839702606201\n","Epoch\t 80 \tLoss\t 2.3356134080395257 \tTime\t 62.3458514213562\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 81 \tLoss\t 2.326222046134398 \tTime\t 62.196608543395996\n","Epoch\t 82 \tLoss\t 2.339995688998822 \tTime\t 61.98067784309387\n","Epoch\t 83 \tLoss\t 2.332147883385727 \tTime\t 62.098745584487915\n","Epoch\t 84 \tLoss\t 2.31785360070848 \tTime\t 62.235291719436646\n","Epoch\t 85 \tLoss\t 2.30695842836321 \tTime\t 62.82519245147705\n","Epoch\t 86 \tLoss\t 2.288399846283431 \tTime\t 62.69261980056763\n","Epoch\t 87 \tLoss\t 2.319456724776435 \tTime\t 62.49110770225525\n","Epoch\t 88 \tLoss\t 2.2864253078539347 \tTime\t 62.1561336517334\n","Epoch\t 89 \tLoss\t 2.285238589208151 \tTime\t 62.57342004776001\n","Epoch\t 90 \tLoss\t 2.2956520712252746 \tTime\t 62.701210498809814\n","Epoch\t 91 \tLoss\t 2.282634666285564 \tTime\t 62.34865427017212\n","Epoch\t 92 \tLoss\t 2.249415816719999 \tTime\t 62.57860851287842\n","Epoch\t 93 \tLoss\t 2.298867203525661 \tTime\t 62.04632544517517\n","Epoch\t 94 \tLoss\t 2.272571929951304 \tTime\t 61.71795105934143\n","Epoch\t 95 \tLoss\t 2.258154277948989 \tTime\t 62.440768003463745\n","Epoch\t 96 \tLoss\t 2.2533581121680664 \tTime\t 69.46487808227539\n","Epoch\t 97 \tLoss\t 2.2559145332611714 \tTime\t 64.37591290473938\n","Epoch\t 98 \tLoss\t 2.2397245058079354 \tTime\t 62.07084560394287\n","Epoch\t 99 \tLoss\t 2.24460914946094 \tTime\t 61.77791500091553\n","Epoch\t 100 \tLoss\t 2.2417818307876587 \tTime\t 62.16763377189636\n","Epoch\t 101 \tLoss\t 2.2494538125303603 \tTime\t 62.12202191352844\n","Epoch\t 102 \tLoss\t 2.228545381850803 \tTime\t 61.96066904067993\n","Epoch\t 103 \tLoss\t 2.2581519269451653 \tTime\t 62.406099796295166\n","Epoch\t 104 \tLoss\t 2.231254001253659 \tTime\t 62.09475898742676\n","Epoch\t 105 \tLoss\t 2.218981511814078 \tTime\t 61.961912631988525\n","Epoch\t 106 \tLoss\t 2.240493395893844 \tTime\t 62.93602514266968\n","Epoch\t 107 \tLoss\t 2.2213702767165664 \tTime\t 62.1355664730072\n","Epoch\t 108 \tLoss\t 2.215183281406914 \tTime\t 62.071308612823486\n","Epoch\t 109 \tLoss\t 2.1868708158276746 \tTime\t 62.23203492164612\n","Epoch\t 110 \tLoss\t 2.2115930724389776 \tTime\t 62.22363495826721\n","Epoch\t 111 \tLoss\t 2.1870954884696254 \tTime\t 62.04686689376831\n","Epoch\t 112 \tLoss\t 2.1945881253665256 \tTime\t 61.80420780181885\n","Epoch\t 113 \tLoss\t 2.2092796699287964 \tTime\t 62.25294327735901\n","Epoch\t 114 \tLoss\t 2.176560158582078 \tTime\t 62.08095622062683\n","Epoch\t 115 \tLoss\t 2.1950079497602797 \tTime\t 62.32181930541992\n","Epoch\t 116 \tLoss\t 2.166607083733549 \tTime\t 62.19894361495972\n","Epoch\t 117 \tLoss\t 2.154681880449511 \tTime\t 62.229175329208374\n","Epoch\t 118 \tLoss\t 2.1761746603189054 \tTime\t 61.92912435531616\n","Epoch\t 119 \tLoss\t 2.1732218732538913 \tTime\t 62.40919780731201\n","Epoch\t 120 \tLoss\t 2.167576526858143 \tTime\t 62.09641242027283\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 121 \tLoss\t 2.1721260068342856 \tTime\t 62.46001696586609\n","Epoch\t 122 \tLoss\t 2.1443287183329 \tTime\t 62.10095024108887\n","Epoch\t 123 \tLoss\t 2.161984282670562 \tTime\t 62.469030141830444\n","Epoch\t 124 \tLoss\t 2.150163008994663 \tTime\t 62.319900035858154\n","Epoch\t 125 \tLoss\t 2.1529698101515624 \tTime\t 62.6106538772583\n","Epoch\t 126 \tLoss\t 2.1642131584206807 \tTime\t 62.051337242126465\n","Epoch\t 127 \tLoss\t 2.1387979713911864 \tTime\t 61.92534899711609\n","Epoch\t 128 \tLoss\t 2.1483015375039014 \tTime\t 62.1825532913208\n","Epoch\t 129 \tLoss\t 2.134381002986554 \tTime\t 62.2631049156189\n","Epoch\t 130 \tLoss\t 2.1300037792048503 \tTime\t 62.37894821166992\n","Epoch\t 131 \tLoss\t 2.1308545845071065 \tTime\t 62.27834177017212\n","Epoch\t 132 \tLoss\t 2.1212158965081285 \tTime\t 61.843464374542236\n","Epoch\t 133 \tLoss\t 2.112990510832403 \tTime\t 62.43735313415527\n","Epoch\t 134 \tLoss\t 2.134889728015231 \tTime\t 62.21586036682129\n","Epoch\t 135 \tLoss\t 2.1225828817210246 \tTime\t 62.54575538635254\n","Epoch\t 136 \tLoss\t 2.101340012452037 \tTime\t 62.395522356033325\n","Epoch\t 137 \tLoss\t 2.0859710617163745 \tTime\t 62.56883096694946\n","Epoch\t 138 \tLoss\t 2.1083341615716207 \tTime\t 62.331172943115234\n","Epoch\t 139 \tLoss\t 2.1158263572712532 \tTime\t 62.46982955932617\n","Epoch\t 140 \tLoss\t 2.083281411338098 \tTime\t 62.70682454109192\n","Epoch\t 141 \tLoss\t 2.11685462956576 \tTime\t 62.65169715881348\n","Epoch\t 142 \tLoss\t 2.07872698479092 \tTime\t 62.48007321357727\n","Epoch\t 143 \tLoss\t 2.091388084224819 \tTime\t 62.56856083869934\n","Epoch\t 144 \tLoss\t 2.080989702460692 \tTime\t 62.206273555755615\n","Epoch\t 145 \tLoss\t 2.087584952718204 \tTime\t 63.08617305755615\n","Epoch\t 146 \tLoss\t 2.069364070892334 \tTime\t 62.572888135910034\n","Epoch\t 147 \tLoss\t 2.078293575454004 \tTime\t 62.32719349861145\n","Epoch\t 148 \tLoss\t 2.0766776320860556 \tTime\t 62.23862385749817\n","Epoch\t 149 \tLoss\t 2.0770518103825677 \tTime\t 62.34228515625\n","Epoch\t 150 \tLoss\t 2.091681477949791 \tTime\t 62.331015825271606\n","Epoch\t 151 \tLoss\t 2.0775531997385714 \tTime\t 62.029260873794556\n","Epoch\t 152 \tLoss\t 2.099353777993586 \tTime\t 62.517722368240356\n","Epoch\t 153 \tLoss\t 2.0929135477419982 \tTime\t 62.41134166717529\n","Epoch\t 154 \tLoss\t 2.0825297488379726 \tTime\t 62.302478313446045\n","Epoch\t 155 \tLoss\t 2.0542835242969475 \tTime\t 63.03791069984436\n","Epoch\t 156 \tLoss\t 2.0653074869175545 \tTime\t 62.30003261566162\n","Epoch\t 157 \tLoss\t 2.066117536161364 \tTime\t 62.627049922943115\n","Epoch\t 158 \tLoss\t 2.0525843150836907 \tTime\t 62.19799995422363\n","Epoch\t 159 \tLoss\t 2.0772309585944893 \tTime\t 62.611557483673096\n","Epoch\t 160 \tLoss\t 2.0493572778308513 \tTime\t 62.714776039123535\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 161 \tLoss\t 2.057036269571363 \tTime\t 62.42929530143738\n","Epoch\t 162 \tLoss\t 2.0607508863370443 \tTime\t 62.28541827201843\n","Epoch\t 163 \tLoss\t 2.0295151914517904 \tTime\t 62.17137169837952\n","Epoch\t 164 \tLoss\t 2.027254372527919 \tTime\t 62.33159017562866\n","Epoch\t 165 \tLoss\t 2.0401282802070537 \tTime\t 62.43506479263306\n","Epoch\t 166 \tLoss\t 2.0530647899686674 \tTime\t 62.13239145278931\n","Epoch\t 167 \tLoss\t 2.040090716991228 \tTime\t 62.36934995651245\n","Epoch\t 168 \tLoss\t 2.0334392232993213 \tTime\t 62.34358596801758\n","Epoch\t 169 \tLoss\t 2.0477097624355984 \tTime\t 62.45487427711487\n","Epoch\t 170 \tLoss\t 2.054734361540411 \tTime\t 62.269535541534424\n","Epoch\t 171 \tLoss\t 2.0324509008643554 \tTime\t 61.72006964683533\n","Epoch\t 172 \tLoss\t 2.0124339197099825 \tTime\t 62.14193367958069\n","Epoch\t 173 \tLoss\t 2.056489476223582 \tTime\t 62.47057032585144\n","Epoch\t 174 \tLoss\t 2.032687952837993 \tTime\t 62.538899660110474\n","Epoch\t 175 \tLoss\t 2.0525552808623955 \tTime\t 62.30966305732727\n","Epoch\t 176 \tLoss\t 2.043057410987382 \tTime\t 61.45891308784485\n","Epoch\t 177 \tLoss\t 2.0419569974093092 \tTime\t 62.42904853820801\n","Epoch\t 178 \tLoss\t 2.0368316038367675 \tTime\t 62.35017800331116\n","Epoch\t 179 \tLoss\t 2.0328134015663384 \tTime\t 62.104320764541626\n","Epoch\t 180 \tLoss\t 2.015307787767391 \tTime\t 61.94715166091919\n","Epoch\t 181 \tLoss\t 2.023488026304343 \tTime\t 62.150617599487305\n","Epoch\t 182 \tLoss\t 2.0143652736526176 \tTime\t 62.06779098510742\n","Epoch\t 183 \tLoss\t 2.0325182344495634 \tTime\t 62.60264778137207\n","Epoch\t 184 \tLoss\t 2.0252872717749213 \tTime\t 62.241321086883545\n","Epoch\t 185 \tLoss\t 2.0419598313951 \tTime\t 62.30402612686157\n","Epoch\t 186 \tLoss\t 2.015131257243992 \tTime\t 62.06522822380066\n","Epoch\t 187 \tLoss\t 2.0214959960622885 \tTime\t 62.270034074783325\n","Epoch\t 188 \tLoss\t 2.0300804646973756 \tTime\t 61.754860639572144\n","Epoch\t 189 \tLoss\t 2.0218581157861295 \tTime\t 62.45113182067871\n","Epoch\t 190 \tLoss\t 2.0317232756270576 \tTime\t 62.200329542160034\n","Epoch\t 191 \tLoss\t 2.035314029025048 \tTime\t 61.8162784576416\n","Epoch\t 192 \tLoss\t 2.007597813901213 \tTime\t 61.8726646900177\n","Epoch\t 193 \tLoss\t 2.031696909481717 \tTime\t 62.46492075920105\n","Epoch\t 194 \tLoss\t 2.0262881087273668 \tTime\t 62.69850015640259\n","Epoch\t 195 \tLoss\t 2.0252012653449145 \tTime\t 62.53227782249451\n","Epoch\t 196 \tLoss\t 2.016572014572694 \tTime\t 62.716023445129395\n","Epoch\t 197 \tLoss\t 2.021738627522262 \tTime\t 62.533180236816406\n","Epoch\t 198 \tLoss\t 2.022794372027682 \tTime\t 62.57870388031006\n","Epoch\t 199 \tLoss\t 2.0110760238981737 \tTime\t 62.397175550460815\n","Epoch\t 200 \tLoss\t 2.02743093992017 \tTime\t 62.32124614715576\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Finished training. Train time was: 12473.293760299683\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 1 \tLoss\t 2.120065036508226 \tTime\t 14.428765296936035\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 2 \tLoss\t 1.793752366734534 \tTime\t 14.455169200897217\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 3 \tLoss\t 1.5962350565133636 \tTime\t 14.454052686691284\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 4 \tLoss\t 1.4679558682687504 \tTime\t 14.47270941734314\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 5 \tLoss\t 1.3792725838336748 \tTime\t 14.458858251571655\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 6 \tLoss\t 1.314844548087759 \tTime\t 14.454031467437744\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 7 \tLoss\t 1.2652270978259057 \tTime\t 14.438453197479248\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 8 \tLoss\t 1.226539369710942 \tTime\t 14.420356512069702\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 9 \tLoss\t 1.196460598522855 \tTime\t 14.458165884017944\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 10 \tLoss\t 1.1711225644829346 \tTime\t 14.460914134979248\n","Finished training. Train time was: 144.51461482048035\n","Accuracy : 62 %\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch\t 1 \tLoss\t 8.999234159787497 \tTime\t 62.70328211784363\n","Epoch\t 2 \tLoss\t 7.590927233298619 \tTime\t 62.989845275878906\n","Epoch\t 3 \tLoss\t 7.376654356718063 \tTime\t 63.17992329597473\n","Epoch\t 4 \tLoss\t 7.277935554583867 \tTime\t 63.150670766830444\n","Epoch\t 5 \tLoss\t 7.206926167011261 \tTime\t 62.80031108856201\n","Epoch\t 6 \tLoss\t 6.99217473467191 \tTime\t 63.31436514854431\n","Epoch\t 7 \tLoss\t 6.782687872648239 \tTime\t 63.797117948532104\n","Epoch\t 8 \tLoss\t 6.593063096205394 \tTime\t 63.19317102432251\n","Epoch\t 9 \tLoss\t 6.368511140346527 \tTime\t 62.88925623893738\n","Epoch\t 10 \tLoss\t 6.031863212585449 \tTime\t 63.23081016540527\n","Epoch\t 11 \tLoss\t 5.843755394220352 \tTime\t 62.732707500457764\n","Epoch\t 12 \tLoss\t 5.5510552028814955 \tTime\t 63.0355269908905\n","Epoch\t 13 \tLoss\t 5.370381752649943 \tTime\t 63.42839550971985\n","Epoch\t 14 \tLoss\t 5.295351316531499 \tTime\t 63.04338264465332\n","Epoch\t 15 \tLoss\t 5.076826423406601 \tTime\t 63.266358852386475\n","Epoch\t 16 \tLoss\t 4.914783914883931 \tTime\t 63.322877168655396\n","Epoch\t 17 \tLoss\t 4.96272815267245 \tTime\t 62.70276236534119\n","Epoch\t 18 \tLoss\t 4.878909935553868 \tTime\t 62.84269189834595\n","Epoch\t 19 \tLoss\t 4.583205709854762 \tTime\t 63.043274879455566\n","Epoch\t 20 \tLoss\t 4.532074143489202 \tTime\t 63.008668422698975\n","Epoch\t 21 \tLoss\t 4.475095868110657 \tTime\t 63.26374387741089\n","Epoch\t 22 \tLoss\t 4.477264195680618 \tTime\t 63.54489278793335\n","Epoch\t 23 \tLoss\t 4.2893045743306475 \tTime\t 62.999154806137085\n","Epoch\t 24 \tLoss\t 4.257956817746162 \tTime\t 63.40363788604736\n","Epoch\t 25 \tLoss\t 4.16360064347585 \tTime\t 63.18116354942322\n","Epoch\t 26 \tLoss\t 4.096879839897156 \tTime\t 63.08774423599243\n","Epoch\t 27 \tLoss\t 4.014191443721454 \tTime\t 62.998308181762695\n","Epoch\t 28 \tLoss\t 3.9771025677522025 \tTime\t 63.010337352752686\n","Epoch\t 29 \tLoss\t 3.987947608033816 \tTime\t 63.28325891494751\n","Epoch\t 30 \tLoss\t 3.9183181474606195 \tTime\t 62.867602586746216\n","Epoch\t 31 \tLoss\t 3.9154609392086663 \tTime\t 62.435558795928955\n","Epoch\t 32 \tLoss\t 3.8290162732203803 \tTime\t 63.130805253982544\n","Epoch\t 33 \tLoss\t 3.778231685360273 \tTime\t 62.63156747817993\n","Epoch\t 34 \tLoss\t 3.7659448782602944 \tTime\t 63.155744314193726\n","Epoch\t 35 \tLoss\t 3.762844905257225 \tTime\t 63.13447332382202\n","Epoch\t 36 \tLoss\t 3.7080164551734924 \tTime\t 63.186384201049805\n","Epoch\t 37 \tLoss\t 3.6858589549859366 \tTime\t 63.43749737739563\n","Epoch\t 38 \tLoss\t 3.681058535973231 \tTime\t 63.6331992149353\n","Epoch\t 39 \tLoss\t 3.6470557947953544 \tTime\t 63.37230205535889\n","Epoch\t 40 \tLoss\t 3.5856663386027017 \tTime\t 63.19990277290344\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 41 \tLoss\t 3.571778511007627 \tTime\t 63.30122709274292\n","Epoch\t 42 \tLoss\t 3.5763974835475287 \tTime\t 63.42800307273865\n","Epoch\t 43 \tLoss\t 3.531268283724785 \tTime\t 63.41014623641968\n","Epoch\t 44 \tLoss\t 3.5240962555011115 \tTime\t 63.57090497016907\n","Epoch\t 45 \tLoss\t 3.5078729540109634 \tTime\t 63.300578594207764\n","Epoch\t 46 \tLoss\t 3.483048195640246 \tTime\t 63.201210737228394\n","Epoch\t 47 \tLoss\t 3.4354286094506583 \tTime\t 63.22893500328064\n","Epoch\t 48 \tLoss\t 3.4332155336936316 \tTime\t 62.91472578048706\n","Epoch\t 49 \tLoss\t 3.4155676861604056 \tTime\t 62.79333305358887\n","Epoch\t 50 \tLoss\t 3.3776969462633133 \tTime\t 63.422996520996094\n","Epoch\t 51 \tLoss\t 3.3905548055966697 \tTime\t 63.13242030143738\n","Epoch\t 52 \tLoss\t 3.3880388339360556 \tTime\t 62.998292684555054\n","Epoch\t 53 \tLoss\t 3.3662812560796738 \tTime\t 63.493276834487915\n","Epoch\t 54 \tLoss\t 3.3573693384726844 \tTime\t 63.08295822143555\n","Epoch\t 55 \tLoss\t 3.3521176278591156 \tTime\t 62.96619963645935\n","Epoch\t 56 \tLoss\t 3.312461862961451 \tTime\t 62.661123514175415\n","Epoch\t 57 \tLoss\t 3.320029387871424 \tTime\t 62.69108986854553\n","Epoch\t 58 \tLoss\t 3.299908310174942 \tTime\t 63.11868476867676\n","Epoch\t 59 \tLoss\t 3.302661041418711 \tTime\t 63.33415508270264\n","Epoch\t 60 \tLoss\t 3.2519483168919883 \tTime\t 63.0297966003418\n","Epoch\t 61 \tLoss\t 3.257785235842069 \tTime\t 63.70791506767273\n","Epoch\t 62 \tLoss\t 3.255291670560837 \tTime\t 63.545883893966675\n","Epoch\t 63 \tLoss\t 3.205218111475309 \tTime\t 63.2826943397522\n","Epoch\t 64 \tLoss\t 3.2418157309293747 \tTime\t 63.158087968826294\n","Epoch\t 65 \tLoss\t 3.214856207370758 \tTime\t 62.955235958099365\n","Epoch\t 66 \tLoss\t 3.1884189744790397 \tTime\t 62.653308391571045\n","Epoch\t 67 \tLoss\t 3.1610357761383057 \tTime\t 62.63967728614807\n","Epoch\t 68 \tLoss\t 3.1860654205083847 \tTime\t 63.1900429725647\n","Epoch\t 69 \tLoss\t 3.1969281236330667 \tTime\t 63.233691930770874\n","Epoch\t 70 \tLoss\t 3.176910469929377 \tTime\t 62.590540647506714\n","Epoch\t 71 \tLoss\t 3.1635481864213943 \tTime\t 63.15847945213318\n","Epoch\t 72 \tLoss\t 3.1336156328519187 \tTime\t 63.82232737541199\n","Epoch\t 73 \tLoss\t 3.1142255514860153 \tTime\t 63.55513906478882\n","Epoch\t 74 \tLoss\t 3.1142507642507553 \tTime\t 63.18006443977356\n","Epoch\t 75 \tLoss\t 3.116492743293444 \tTime\t 63.150365114212036\n","Epoch\t 76 \tLoss\t 3.1079015036424003 \tTime\t 64.00818490982056\n","Epoch\t 77 \tLoss\t 3.1091011414925256 \tTime\t 63.0855450630188\n","Epoch\t 78 \tLoss\t 3.0698407888412476 \tTime\t 62.2849326133728\n","Epoch\t 79 \tLoss\t 3.06663183371226 \tTime\t 62.918362617492676\n","Epoch\t 80 \tLoss\t 3.0475236773490906 \tTime\t 63.330323696136475\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 81 \tLoss\t 3.0721292197704315 \tTime\t 63.705488443374634\n","Epoch\t 82 \tLoss\t 3.0432177682717643 \tTime\t 63.02504253387451\n","Epoch\t 83 \tLoss\t 3.02127272884051 \tTime\t 63.26253080368042\n","Epoch\t 84 \tLoss\t 3.0321636448303857 \tTime\t 63.32146215438843\n","Epoch\t 85 \tLoss\t 3.0272626479466758 \tTime\t 63.3647723197937\n","Epoch\t 86 \tLoss\t 3.0155745347340903 \tTime\t 63.200514793395996\n","Epoch\t 87 \tLoss\t 3.00803550084432 \tTime\t 63.60897612571716\n","Epoch\t 88 \tLoss\t 2.967238664627075 \tTime\t 62.823750019073486\n","Epoch\t 89 \tLoss\t 2.9953334679206214 \tTime\t 63.47988152503967\n","Epoch\t 90 \tLoss\t 2.9775156329075494 \tTime\t 62.870309352874756\n","Epoch\t 91 \tLoss\t 2.9439546316862106 \tTime\t 63.74750471115112\n","Epoch\t 92 \tLoss\t 3.0020147363344827 \tTime\t 63.10807275772095\n","Epoch\t 93 \tLoss\t 2.96482852101326 \tTime\t 62.61656737327576\n","Epoch\t 94 \tLoss\t 2.932124078273773 \tTime\t 62.96536374092102\n","Epoch\t 95 \tLoss\t 2.9651814748843512 \tTime\t 63.787131786346436\n","Epoch\t 96 \tLoss\t 2.9624842753012977 \tTime\t 63.02279305458069\n","Epoch\t 97 \tLoss\t 2.9065530200799308 \tTime\t 63.72167134284973\n","Epoch\t 98 \tLoss\t 2.922554994622866 \tTime\t 63.575379610061646\n","Epoch\t 99 \tLoss\t 2.9219174732764563 \tTime\t 62.764169692993164\n","Epoch\t 100 \tLoss\t 2.894816761215528 \tTime\t 63.11906862258911\n","Epoch\t 101 \tLoss\t 2.8881775786479316 \tTime\t 63.88292479515076\n","Epoch\t 102 \tLoss\t 2.8952907075484595 \tTime\t 63.840980768203735\n","Epoch\t 103 \tLoss\t 2.874278793732325 \tTime\t 63.07992339134216\n","Epoch\t 104 \tLoss\t 2.85753566523393 \tTime\t 63.59431481361389\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0P0RFK-ckSVM","executionInfo":{"status":"error","timestamp":1601137248726,"user_tz":-540,"elapsed":10888715,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"1be00d74-0ac4-4bf6-e9e1-0309ba5ed14c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batch_size_list = [1024]\n","temperature_list = [0.01, 0.05, 0.1, 0.5, 1.0]\n","n_epoch_list = [300, 400]\n","\n","batch_loss =[]\n","temperature_loss =[]\n","epoch_loss =[]\n","\n","batch_acc =[]\n","temperature_acc =[]\n","epoch_acc =[]\n","\n","# batch_size test\n","\n","for bs in batch_size_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(bs)\n","  loss = train_param(net, tl, batch_size=bs)\n","  batch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifier(net, testl)\n","  batch_acc.append((bs, acc))\n","  save_model(net, \"simclr_batch_{}.pt\".format(bs))\n","\n","for n in n_epoch_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(256)\n","  loss = train_param(net, tl, n_epoch=n)\n","  epoch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifier(net, testl)\n","  epoch_acc.append((n, acc))\n","  save_model(net, \"simclr_epoch_{}.pt\".format(n))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 40\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 80\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch\t 161 \tLoss\t 3.025838519136111 \tTime\t 58.324153900146484\n","Epoch\t 162 \tLoss\t 2.9524448613325753 \tTime\t 58.944129943847656\n","Epoch\t 163 \tLoss\t 2.9138349493344626 \tTime\t 58.785212993621826\n","Epoch\t 164 \tLoss\t 2.897844890753428 \tTime\t 58.29815626144409\n","Epoch\t 165 \tLoss\t 2.8998397241036096 \tTime\t 58.26653432846069\n","Epoch\t 166 \tLoss\t 2.9163595785697303 \tTime\t 58.03367781639099\n","Epoch\t 167 \tLoss\t 2.916248386104902 \tTime\t 58.27595257759094\n","Epoch\t 168 \tLoss\t 2.923377200961113 \tTime\t 57.924302101135254\n","Epoch\t 169 \tLoss\t 2.93230672677358 \tTime\t 58.34820890426636\n","Epoch\t 170 \tLoss\t 2.9326183249553046 \tTime\t 57.98567748069763\n","Epoch\t 171 \tLoss\t 2.9713380187749863 \tTime\t 58.22328805923462\n","Epoch\t 172 \tLoss\t 2.972802057862282 \tTime\t 58.33898663520813\n","Epoch\t 173 \tLoss\t 2.9993426154057183 \tTime\t 58.02988791465759\n","Epoch\t 174 \tLoss\t 2.9912127256393433 \tTime\t 58.812517166137695\n","Epoch\t 175 \tLoss\t 2.9972637047370276 \tTime\t 58.54034209251404\n","Epoch\t 176 \tLoss\t 2.9664755165576935 \tTime\t 59.16810989379883\n","Epoch\t 177 \tLoss\t 3.019042784969012 \tTime\t 58.64586544036865\n","Epoch\t 178 \tLoss\t 3.02206851541996 \tTime\t 58.46705985069275\n","Epoch\t 179 \tLoss\t 3.0380345582962036 \tTime\t 58.47673153877258\n","Epoch\t 180 \tLoss\t 3.0282533168792725 \tTime\t 58.50779366493225\n","Epoch\t 181 \tLoss\t 3.048598602414131 \tTime\t 59.12489366531372\n","Epoch\t 182 \tLoss\t 3.061555420358976 \tTime\t 59.253864765167236\n","Epoch\t 183 \tLoss\t 3.0193744550148645 \tTime\t 60.08485507965088\n","Epoch\t 184 \tLoss\t 3.039363523324331 \tTime\t 58.8903648853302\n","Epoch\t 185 \tLoss\t 3.0311467895905175 \tTime\t 58.47486090660095\n","Epoch\t 186 \tLoss\t 2.998408243060112 \tTime\t 59.33334016799927\n","Epoch\t 187 \tLoss\t 2.9839386393626532 \tTime\t 58.73655867576599\n","Epoch\t 188 \tLoss\t 2.958614776531855 \tTime\t 58.504244804382324\n","Epoch\t 189 \tLoss\t 2.957229048013687 \tTime\t 58.244750022888184\n","Epoch\t 190 \tLoss\t 2.9602140188217163 \tTime\t 57.94489240646362\n","Epoch\t 191 \tLoss\t 2.981874351700147 \tTime\t 58.42716193199158\n","Epoch\t 192 \tLoss\t 2.940755824247996 \tTime\t 57.726932764053345\n","Epoch\t 193 \tLoss\t 2.923431177934011 \tTime\t 58.04587006568909\n","Epoch\t 194 \tLoss\t 2.962768862644831 \tTime\t 57.86599087715149\n","Epoch\t 195 \tLoss\t 2.9590489914019904 \tTime\t 57.81419515609741\n","Epoch\t 196 \tLoss\t 2.928673510750135 \tTime\t 57.97178864479065\n","Epoch\t 197 \tLoss\t 2.9172053237756095 \tTime\t 58.194336891174316\n","Epoch\t 198 \tLoss\t 2.909887840350469 \tTime\t 58.013630390167236\n","Epoch\t 199 \tLoss\t 2.9037252912918725 \tTime\t 58.74839496612549\n","Epoch\t 200 \tLoss\t 2.9012409895658493 \tTime\t 59.25947093963623\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Finished training. Train time was: 2339.9377558231354\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 1 \tLoss\t 2.231981724500656 \tTime\t 7.9355974197387695\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 2 \tLoss\t 1.9928229128321011 \tTime\t 7.757532119750977\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 3 \tLoss\t 1.818840170900027 \tTime\t 7.684316873550415\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 4 \tLoss\t 1.6868016521135967 \tTime\t 7.736876726150513\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 5 \tLoss\t 1.585141693552335 \tTime\t 7.756982326507568\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 6 \tLoss\t 1.5057288656632106 \tTime\t 7.836111068725586\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 7 \tLoss\t 1.4443691050012906 \tTime\t 7.821174383163452\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 8 \tLoss\t 1.3921836366256077 \tTime\t 7.794016361236572\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 9 \tLoss\t 1.3503742466370265 \tTime\t 7.8337554931640625\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 10 \tLoss\t 1.316394900282224 \tTime\t 7.907032251358032\n","Finished training. Train time was: 78.07871723175049\n","Accuracy : 58 %\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch\t 161 \tLoss\t 6.3436768531799315 \tTime\t 65.24152493476868\n","Epoch\t 162 \tLoss\t 6.029906290005415 \tTime\t 63.14412808418274\n","Epoch\t 163 \tLoss\t 5.726467274396848 \tTime\t 63.43172097206116\n","Epoch\t 164 \tLoss\t 5.396226357191037 \tTime\t 63.67893075942993\n","Epoch\t 165 \tLoss\t 5.049018497956105 \tTime\t 64.29025793075562\n","Epoch\t 166 \tLoss\t 4.6085842083661985 \tTime\t 64.10253047943115\n","Epoch\t 167 \tLoss\t 4.172999982344798 \tTime\t 64.55337834358215\n","Epoch\t 168 \tLoss\t 3.894860475491255 \tTime\t 64.2829442024231\n","Epoch\t 169 \tLoss\t 3.648857583755102 \tTime\t 63.90051817893982\n","Epoch\t 170 \tLoss\t 3.474528733277932 \tTime\t 65.26160001754761\n","Epoch\t 171 \tLoss\t 3.365146113664676 \tTime\t 63.099854946136475\n","Epoch\t 172 \tLoss\t 3.250947902141473 \tTime\t 61.77249336242676\n","Epoch\t 173 \tLoss\t 3.153822948993781 \tTime\t 61.78238391876221\n","Epoch\t 174 \tLoss\t 3.0490389420435977 \tTime\t 62.23908448219299\n","Epoch\t 175 \tLoss\t 2.9868387955885667 \tTime\t 61.73824167251587\n","Epoch\t 176 \tLoss\t 2.9169247553898736 \tTime\t 63.04592204093933\n","Epoch\t 177 \tLoss\t 2.866523908957457 \tTime\t 63.16303086280823\n","Epoch\t 178 \tLoss\t 2.813518264966133 \tTime\t 64.35115432739258\n","Epoch\t 179 \tLoss\t 2.7621838153936924 \tTime\t 66.76140117645264\n","Epoch\t 180 \tLoss\t 2.7153068628066626 \tTime\t 64.06536936759949\n","Epoch\t 181 \tLoss\t 2.661730136626806 \tTime\t 63.17997074127197\n","Epoch\t 182 \tLoss\t 2.62223284917 \tTime\t 62.81652641296387\n","Epoch\t 183 \tLoss\t 2.604779094304794 \tTime\t 63.510979890823364\n","Epoch\t 184 \tLoss\t 2.622213939520029 \tTime\t 63.66861343383789\n","Epoch\t 185 \tLoss\t 2.5603848775227864 \tTime\t 63.23294162750244\n","Epoch\t 186 \tLoss\t 2.544597438665537 \tTime\t 63.62873363494873\n","Epoch\t 187 \tLoss\t 2.536686200361985 \tTime\t 64.17304515838623\n","Epoch\t 188 \tLoss\t 2.4825620687924896 \tTime\t 64.5493996143341\n","Epoch\t 189 \tLoss\t 2.4810220828423133 \tTime\t 64.9127824306488\n","Epoch\t 190 \tLoss\t 2.4326466902708397 \tTime\t 65.18957352638245\n","Epoch\t 191 \tLoss\t 2.413046234081953 \tTime\t 64.79697847366333\n","Epoch\t 192 \tLoss\t 2.3884199325854962 \tTime\t 64.75768089294434\n","Epoch\t 193 \tLoss\t 2.363469790801024 \tTime\t 64.65631055831909\n","Epoch\t 194 \tLoss\t 2.317342846821516 \tTime\t 64.48535513877869\n","Epoch\t 195 \tLoss\t 2.3054896800945968 \tTime\t 66.39388036727905\n","Epoch\t 196 \tLoss\t 2.2933107883502277 \tTime\t 67.28241062164307\n","Epoch\t 197 \tLoss\t 2.2587482403486203 \tTime\t 64.36459112167358\n","Epoch\t 198 \tLoss\t 2.2572465713207537 \tTime\t 63.27545690536499\n","Epoch\t 199 \tLoss\t 2.2531380439415956 \tTime\t 63.65109586715698\n","Epoch\t 200 \tLoss\t 2.2145195056230595 \tTime\t 64.4714629650116\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 201 \tLoss\t 2.1958572522187843 \tTime\t 63.70380759239197\n","Epoch\t 202 \tLoss\t 2.2174782037734984 \tTime\t 63.44631052017212\n","Epoch\t 203 \tLoss\t 2.1798630744982987 \tTime\t 63.09532356262207\n","Epoch\t 204 \tLoss\t 2.1327875822018356 \tTime\t 63.44514870643616\n","Epoch\t 205 \tLoss\t 2.1420980331225272 \tTime\t 63.351311922073364\n","Epoch\t 206 \tLoss\t 2.1599024735964263 \tTime\t 63.03366708755493\n","Epoch\t 207 \tLoss\t 2.1249086300532025 \tTime\t 63.19484353065491\n","Epoch\t 208 \tLoss\t 2.0969729869793623 \tTime\t 64.04307985305786\n","Epoch\t 209 \tLoss\t 2.097823116718194 \tTime\t 63.958789110183716\n","Epoch\t 210 \tLoss\t 2.093963763041374 \tTime\t 64.10292768478394\n","Epoch\t 211 \tLoss\t 2.085120333158053 \tTime\t 63.95577311515808\n","Epoch\t 212 \tLoss\t 2.1019995163648555 \tTime\t 63.651511907577515\n","Epoch\t 213 \tLoss\t 2.0622044251515317 \tTime\t 63.763057708740234\n","Epoch\t 214 \tLoss\t 2.0717170354647516 \tTime\t 63.503087520599365\n","Epoch\t 215 \tLoss\t 2.052718659547659 \tTime\t 64.3009340763092\n","Epoch\t 216 \tLoss\t 2.0440959374109906 \tTime\t 64.30689692497253\n","Epoch\t 217 \tLoss\t 2.049030061868521 \tTime\t 63.968233585357666\n","Epoch\t 218 \tLoss\t 2.0369607106233256 \tTime\t 64.21990871429443\n","Epoch\t 219 \tLoss\t 2.025485963699145 \tTime\t 64.53483724594116\n","Epoch\t 220 \tLoss\t 1.9983983944623898 \tTime\t 64.30541634559631\n","Epoch\t 221 \tLoss\t 1.9989222881121513 \tTime\t 64.44385623931885\n","Epoch\t 222 \tLoss\t 1.9918455068881695 \tTime\t 64.59181618690491\n","Epoch\t 223 \tLoss\t 2.0048643020483166 \tTime\t 64.90823316574097\n","Epoch\t 224 \tLoss\t 1.9888805157099014 \tTime\t 65.35951495170593\n","Epoch\t 225 \tLoss\t 1.9814096377446102 \tTime\t 65.19750308990479\n","Epoch\t 226 \tLoss\t 1.9613912808589447 \tTime\t 65.506516456604\n","Epoch\t 227 \tLoss\t 1.9745054556773258 \tTime\t 64.94987154006958\n","Epoch\t 228 \tLoss\t 1.9656080313217945 \tTime\t 64.55309462547302\n","Epoch\t 229 \tLoss\t 1.931485179754404 \tTime\t 65.02612090110779\n","Epoch\t 230 \tLoss\t 1.929470713933309 \tTime\t 63.73406267166138\n","Epoch\t 231 \tLoss\t 1.9404045985295222 \tTime\t 64.6824221611023\n","Epoch\t 232 \tLoss\t 1.9279515504837037 \tTime\t 64.32017993927002\n","Epoch\t 233 \tLoss\t 1.934166441208277 \tTime\t 62.952000856399536\n","Epoch\t 234 \tLoss\t 1.934019866356483 \tTime\t 61.919392347335815\n","Epoch\t 235 \tLoss\t 1.9004372853499192 \tTime\t 61.16493535041809\n","Epoch\t 236 \tLoss\t 1.9197883807695828 \tTime\t 60.77614140510559\n","Epoch\t 237 \tLoss\t 1.925673335026472 \tTime\t 60.75757431983948\n","Epoch\t 238 \tLoss\t 1.9151930552262526 \tTime\t 60.74181795120239\n","Epoch\t 239 \tLoss\t 1.9136687504939545 \tTime\t 60.746702909469604\n","Epoch\t 240 \tLoss\t 1.9149715252411672 \tTime\t 60.71768760681152\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 241 \tLoss\t 1.8885360919512235 \tTime\t 60.63133716583252\n","Epoch\t 242 \tLoss\t 1.8891059961074437 \tTime\t 60.586982011795044\n","Epoch\t 243 \tLoss\t 1.888933706894899 \tTime\t 60.934001207351685\n","Epoch\t 244 \tLoss\t 1.871636568582975 \tTime\t 61.024508476257324\n","Epoch\t 245 \tLoss\t 1.8784592506213067 \tTime\t 60.742316484451294\n","Epoch\t 246 \tLoss\t 1.8753813480719541 \tTime\t 61.01225233078003\n","Epoch\t 247 \tLoss\t 1.8574589686516003 \tTime\t 61.3157799243927\n","Epoch\t 248 \tLoss\t 1.894196627690242 \tTime\t 60.807679414749146\n","Epoch\t 249 \tLoss\t 1.850847282165136 \tTime\t 60.78534173965454\n","Epoch\t 250 \tLoss\t 1.8556322085551726 \tTime\t 61.5860915184021\n","Epoch\t 251 \tLoss\t 1.8550563408778264 \tTime\t 61.287665367126465\n","Epoch\t 252 \tLoss\t 1.8411032132613354 \tTime\t 61.06472325325012\n","Epoch\t 253 \tLoss\t 1.8523198940815069 \tTime\t 60.769092321395874\n","Epoch\t 254 \tLoss\t 1.8476056520755475 \tTime\t 60.83051109313965\n","Epoch\t 255 \tLoss\t 1.8517545596147196 \tTime\t 60.63512659072876\n","Epoch\t 256 \tLoss\t 1.8164067060519486 \tTime\t 60.77400827407837\n","Epoch\t 257 \tLoss\t 1.8284644194138355 \tTime\t 60.51640033721924\n","Epoch\t 258 \tLoss\t 1.8488453492140158 \tTime\t 60.58897566795349\n","Epoch\t 259 \tLoss\t 1.8186813709063407 \tTime\t 60.5603666305542\n","Epoch\t 260 \tLoss\t 1.8151849826176962 \tTime\t 60.53579807281494\n","Epoch\t 261 \tLoss\t 1.7984365426577054 \tTime\t 60.59222340583801\n","Epoch\t 262 \tLoss\t 1.8092146048179039 \tTime\t 60.470210313797\n","Epoch\t 263 \tLoss\t 1.7971085334435488 \tTime\t 60.62660551071167\n","Epoch\t 264 \tLoss\t 1.809679396947225 \tTime\t 60.479034185409546\n","Epoch\t 265 \tLoss\t 1.794041639719254 \tTime\t 60.412137031555176\n","Epoch\t 266 \tLoss\t 1.8061546698594704 \tTime\t 60.58168411254883\n","Epoch\t 267 \tLoss\t 1.7961642717703794 \tTime\t 60.509279012680054\n","Epoch\t 268 \tLoss\t 1.792485737800598 \tTime\t 60.168434858322144\n","Epoch\t 269 \tLoss\t 1.7927489629158606 \tTime\t 60.5376250743866\n","Epoch\t 270 \tLoss\t 1.785127304150508 \tTime\t 61.208091735839844\n","Epoch\t 271 \tLoss\t 1.794164313414158 \tTime\t 60.43637537956238\n","Epoch\t 272 \tLoss\t 1.7654725080881364 \tTime\t 60.3508722782135\n","Epoch\t 273 \tLoss\t 1.7592106256729518 \tTime\t 60.34617304801941\n","Epoch\t 274 \tLoss\t 1.7785549365557156 \tTime\t 60.54938316345215\n","Epoch\t 275 \tLoss\t 1.7842976368390597 \tTime\t 60.74087190628052\n","Epoch\t 276 \tLoss\t 1.7561231441986866 \tTime\t 60.68875598907471\n","Epoch\t 277 \tLoss\t 1.7758203078538943 \tTime\t 60.36745023727417\n","Epoch\t 278 \tLoss\t 1.7750508369543614 \tTime\t 60.550514936447144\n","Epoch\t 279 \tLoss\t 1.7568424616104517 \tTime\t 60.51558804512024\n","Epoch\t 280 \tLoss\t 1.743018619219462 \tTime\t 60.76575231552124\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 281 \tLoss\t 1.7541773734948574 \tTime\t 60.43547797203064\n","Epoch\t 282 \tLoss\t 1.75624577999115 \tTime\t 60.42679047584534\n","Epoch\t 283 \tLoss\t 1.7480149171291253 \tTime\t 60.54533576965332\n","Epoch\t 284 \tLoss\t 1.7421163491713696 \tTime\t 60.719687938690186\n","Epoch\t 285 \tLoss\t 1.7489618081312912 \tTime\t 61.059937953948975\n","Epoch\t 286 \tLoss\t 1.7449170106496565 \tTime\t 60.94729495048523\n","Epoch\t 287 \tLoss\t 1.7436298034129998 \tTime\t 60.615753173828125\n","Epoch\t 288 \tLoss\t 1.741658474237491 \tTime\t 60.716360569000244\n","Epoch\t 289 \tLoss\t 1.7262356929289988 \tTime\t 60.67492890357971\n","Epoch\t 290 \tLoss\t 1.746130270224351 \tTime\t 62.08648061752319\n","Epoch\t 291 \tLoss\t 1.7389606940440643 \tTime\t 62.35796761512756\n","Epoch\t 292 \tLoss\t 1.7446353270457342 \tTime\t 62.919652462005615\n","Epoch\t 293 \tLoss\t 1.7137002834906945 \tTime\t 63.40065908432007\n","Epoch\t 294 \tLoss\t 1.7358226091433795 \tTime\t 63.638906955718994\n","Epoch\t 295 \tLoss\t 1.722877911420969 \tTime\t 64.29074263572693\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-ee3cb18e8b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-318e10e1c00b>\u001b[0m in \u001b[0;36mtrain_param\u001b[0;34m(net, loader, batch_size, temperature, n_epoch)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mzi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mfeat_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mfeat_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-802561630d34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, norm_feat)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m### 3. Logit vector by the linear classifier (logit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm_feat\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m           \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-802561630d34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-802561630d34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2012\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"XjvA9JymOb0h","outputId":"4288fce1-de19-481b-f4d7-960a4377da00","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["n_epoch_list = [300, 400]\n","\n","batch_loss =[]\n","temperature_loss =[]\n","epoch_loss =[]\n","\n","batch_acc =[]\n","temperature_acc =[]\n","epoch_acc =[]\n","\n","for n in n_epoch_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(256)\n","  loss = train_param(net, tl, n_epoch=n)\n","  epoch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifier(net, testl)\n","  epoch_acc.append((n, acc))\n","  save_model(net, \"simclr_epoch_{}.pt\".format(n))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch\t 1 \tLoss\t 6.415753161601531 \tTime\t 64.61478662490845\n","Epoch\t 2 \tLoss\t 6.004381700662466 \tTime\t 65.13082933425903\n","Epoch\t 3 \tLoss\t 5.762549043313051 \tTime\t 65.24457550048828\n","Epoch\t 4 \tLoss\t 5.49409361130152 \tTime\t 65.22883725166321\n","Epoch\t 5 \tLoss\t 5.13580809373122 \tTime\t 64.10367918014526\n","Epoch\t 6 \tLoss\t 4.695446173350017 \tTime\t 62.14321160316467\n","Epoch\t 7 \tLoss\t 4.229327650559254 \tTime\t 61.597044706344604\n","Epoch\t 8 \tLoss\t 3.9559252017583604 \tTime\t 60.75789999961853\n","Epoch\t 9 \tLoss\t 3.708689544139764 \tTime\t 60.77405786514282\n","Epoch\t 10 \tLoss\t 3.535586954997136 \tTime\t 60.94543981552124\n","Epoch\t 11 \tLoss\t 3.371959895354051 \tTime\t 60.80849289894104\n","Epoch\t 12 \tLoss\t 3.2698712593469863 \tTime\t 60.94319987297058\n","Epoch\t 13 \tLoss\t 3.161718894273807 \tTime\t 60.641711950302124\n","Epoch\t 14 \tLoss\t 3.049794233762301 \tTime\t 60.89781332015991\n","Epoch\t 15 \tLoss\t 2.9663420750544622 \tTime\t 60.77525591850281\n","Epoch\t 16 \tLoss\t 2.899326869768974 \tTime\t 60.977288484573364\n","Epoch\t 17 \tLoss\t 2.864108544129592 \tTime\t 61.0112361907959\n","Epoch\t 18 \tLoss\t 2.819056272506714 \tTime\t 61.24881839752197\n","Epoch\t 19 \tLoss\t 2.763138851752648 \tTime\t 61.04505133628845\n","Epoch\t 20 \tLoss\t 2.7417287496420055 \tTime\t 60.746941804885864\n","Epoch\t 21 \tLoss\t 2.674386399831527 \tTime\t 60.76644039154053\n","Epoch\t 22 \tLoss\t 2.6402547273880397 \tTime\t 61.11629319190979\n","Epoch\t 23 \tLoss\t 2.596102794011434 \tTime\t 60.88236665725708\n","Epoch\t 24 \tLoss\t 2.5931270183661046 \tTime\t 60.861212491989136\n","Epoch\t 25 \tLoss\t 2.560936460739527 \tTime\t 60.63397407531738\n","Epoch\t 26 \tLoss\t 2.526129860755725 \tTime\t 60.68857550621033\n","Epoch\t 27 \tLoss\t 2.4984563191731772 \tTime\t 61.07665538787842\n","Epoch\t 28 \tLoss\t 2.4689813956236226 \tTime\t 60.68830132484436\n","Epoch\t 29 \tLoss\t 2.4236565369826097 \tTime\t 60.66759920120239\n","Epoch\t 30 \tLoss\t 2.4090483616559935 \tTime\t 60.55190896987915\n","Epoch\t 31 \tLoss\t 2.401244126833402 \tTime\t 60.618353605270386\n","Epoch\t 32 \tLoss\t 2.3743093765698946 \tTime\t 60.88581657409668\n","Epoch\t 33 \tLoss\t 2.342904829367613 \tTime\t 60.44051814079285\n","Epoch\t 34 \tLoss\t 2.3338804880777997 \tTime\t 60.54267644882202\n","Epoch\t 35 \tLoss\t 2.3090816693428233 \tTime\t 60.54515528678894\n","Epoch\t 36 \tLoss\t 2.2808368786787376 \tTime\t 60.52591562271118\n","Epoch\t 37 \tLoss\t 2.2734225095846714 \tTime\t 60.58088421821594\n","Epoch\t 38 \tLoss\t 2.244852827145503 \tTime\t 60.76274633407593\n","Epoch\t 39 \tLoss\t 2.2174793665225687 \tTime\t 60.72981333732605\n","Epoch\t 40 \tLoss\t 2.194899856738555 \tTime\t 60.65304684638977\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 41 \tLoss\t 2.174418674982511 \tTime\t 60.87355923652649\n","Epoch\t 42 \tLoss\t 2.1665886169824846 \tTime\t 60.66361331939697\n","Epoch\t 43 \tLoss\t 2.196260477335025 \tTime\t 61.053744316101074\n","Epoch\t 44 \tLoss\t 2.140356835952172 \tTime\t 60.78885054588318\n","Epoch\t 45 \tLoss\t 2.1312046809074205 \tTime\t 60.660494327545166\n","Epoch\t 46 \tLoss\t 2.118422175065065 \tTime\t 60.78604555130005\n","Epoch\t 47 \tLoss\t 2.122029938453283 \tTime\t 61.829716205596924\n","Epoch\t 48 \tLoss\t 2.110147596628238 \tTime\t 62.571380376815796\n","Epoch\t 49 \tLoss\t 2.113157363426991 \tTime\t 61.083598136901855\n","Epoch\t 50 \tLoss\t 2.0856999464524097 \tTime\t 60.8581326007843\n","Epoch\t 51 \tLoss\t 2.0937616831217056 \tTime\t 60.9965558052063\n","Epoch\t 52 \tLoss\t 2.0694159788963122 \tTime\t 60.991151571273804\n","Epoch\t 53 \tLoss\t 2.06508359175462 \tTime\t 61.37934851646423\n","Epoch\t 54 \tLoss\t 2.066987961377853 \tTime\t 60.96243906021118\n","Epoch\t 55 \tLoss\t 2.042381836206485 \tTime\t 61.08410882949829\n","Epoch\t 56 \tLoss\t 2.0477287775430923 \tTime\t 61.409454584121704\n","Epoch\t 57 \tLoss\t 2.0080618870563995 \tTime\t 62.14908766746521\n","Epoch\t 58 \tLoss\t 2.0096480974784265 \tTime\t 63.06278109550476\n","Epoch\t 59 \tLoss\t 2.008037130649273 \tTime\t 63.98258709907532\n","Epoch\t 60 \tLoss\t 1.97112707786071 \tTime\t 64.5794780254364\n","Epoch\t 61 \tLoss\t 1.9950941642125448 \tTime\t 65.15407395362854\n","Epoch\t 62 \tLoss\t 1.9903385223486485 \tTime\t 65.21453666687012\n","Epoch\t 63 \tLoss\t 1.9662004745923556 \tTime\t 65.12895846366882\n","Epoch\t 64 \tLoss\t 1.9736967826500917 \tTime\t 65.5312511920929\n","Epoch\t 65 \tLoss\t 1.9562103846134284 \tTime\t 65.82876992225647\n","Epoch\t 66 \tLoss\t 1.9630202085543902 \tTime\t 66.21546530723572\n","Epoch\t 67 \tLoss\t 1.9563898055981368 \tTime\t 66.39530849456787\n","Epoch\t 68 \tLoss\t 1.9492680641321036 \tTime\t 65.83387088775635\n","Epoch\t 69 \tLoss\t 1.9463519126940996 \tTime\t 66.08763003349304\n","Epoch\t 70 \tLoss\t 1.9358549087475507 \tTime\t 66.37939095497131\n","Epoch\t 71 \tLoss\t 1.9426166546650423 \tTime\t 66.45340943336487\n","Epoch\t 72 \tLoss\t 1.9296531622226423 \tTime\t 66.6648645401001\n","Epoch\t 73 \tLoss\t 1.9093656093646318 \tTime\t 66.52868294715881\n","Epoch\t 74 \tLoss\t 1.9201104751000038 \tTime\t 66.79288244247437\n","Epoch\t 75 \tLoss\t 1.9141809249535584 \tTime\t 66.8367760181427\n","Epoch\t 76 \tLoss\t 1.9072953205842238 \tTime\t 65.53549933433533\n","Epoch\t 77 \tLoss\t 1.9197381899907038 \tTime\t 63.06040954589844\n","Epoch\t 78 \tLoss\t 1.9136706321667403 \tTime\t 62.3767569065094\n","Epoch\t 79 \tLoss\t 1.8957033236821492 \tTime\t 61.62528920173645\n","Epoch\t 80 \tLoss\t 1.8701080108300234 \tTime\t 61.345871686935425\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 81 \tLoss\t 1.898519411453834 \tTime\t 61.22209095954895\n","Epoch\t 82 \tLoss\t 1.8926932585545075 \tTime\t 61.675445318222046\n","Epoch\t 83 \tLoss\t 1.8707816509100108 \tTime\t 61.47704553604126\n","Epoch\t 84 \tLoss\t 1.859295567488059 \tTime\t 61.15506982803345\n","Epoch\t 85 \tLoss\t 1.8732129231477395 \tTime\t 61.449992179870605\n","Epoch\t 86 \tLoss\t 1.8560498567727897 \tTime\t 61.101417779922485\n","Epoch\t 87 \tLoss\t 1.856791734084105 \tTime\t 61.50731158256531\n","Epoch\t 88 \tLoss\t 1.8632006296744714 \tTime\t 61.102675676345825\n","Epoch\t 89 \tLoss\t 1.8487915595372517 \tTime\t 61.013012647628784\n","Epoch\t 90 \tLoss\t 1.8541652881182158 \tTime\t 61.311463594436646\n","Epoch\t 91 \tLoss\t 1.8178584098815918 \tTime\t 61.2101149559021\n","Epoch\t 92 \tLoss\t 1.8349000533421835 \tTime\t 61.22675538063049\n","Epoch\t 93 \tLoss\t 1.8311048036966568 \tTime\t 61.14404630661011\n","Epoch\t 94 \tLoss\t 1.8378170196826642 \tTime\t 61.18970561027527\n","Epoch\t 95 \tLoss\t 1.8249009957680336 \tTime\t 61.38814949989319\n","Epoch\t 96 \tLoss\t 1.8323142552987124 \tTime\t 61.10684084892273\n","Epoch\t 97 \tLoss\t 1.8391292290809826 \tTime\t 61.31646704673767\n","Epoch\t 98 \tLoss\t 1.8208943635989459 \tTime\t 61.207404375076294\n","Epoch\t 99 \tLoss\t 1.8195351539514004 \tTime\t 61.1252965927124\n","Epoch\t 100 \tLoss\t 1.8049861553387765 \tTime\t 61.065929889678955\n","Epoch\t 101 \tLoss\t 1.8004035234451294 \tTime\t 61.16926026344299\n","Epoch\t 102 \tLoss\t 1.8026300149086194 \tTime\t 61.143415212631226\n","Epoch\t 103 \tLoss\t 1.8199914278128209 \tTime\t 61.004536628723145\n","Epoch\t 104 \tLoss\t 1.7989557944811307 \tTime\t 61.106624603271484\n","Epoch\t 105 \tLoss\t 1.7857571033331063 \tTime\t 61.307852029800415\n","Epoch\t 106 \tLoss\t 1.785000232549814 \tTime\t 61.325393199920654\n","Epoch\t 107 \tLoss\t 1.7964883082952254 \tTime\t 61.37665343284607\n","Epoch\t 108 \tLoss\t 1.7694061450469187 \tTime\t 61.41164231300354\n","Epoch\t 109 \tLoss\t 1.7793554599468524 \tTime\t 61.06971859931946\n","Epoch\t 110 \tLoss\t 1.7827524937116184 \tTime\t 61.2711136341095\n","Epoch\t 111 \tLoss\t 1.766014605302077 \tTime\t 61.27950716018677\n","Epoch\t 112 \tLoss\t 1.7713615429707064 \tTime\t 61.29580354690552\n","Epoch\t 113 \tLoss\t 1.770800636976193 \tTime\t 61.10277700424194\n","Epoch\t 114 \tLoss\t 1.7662595687768399 \tTime\t 61.07448625564575\n","Epoch\t 115 \tLoss\t 1.7580963348731016 \tTime\t 61.28382349014282\n","Epoch\t 116 \tLoss\t 1.7489450118480585 \tTime\t 61.18469834327698\n","Epoch\t 117 \tLoss\t 1.7441817888846765 \tTime\t 61.13642644882202\n","Epoch\t 118 \tLoss\t 1.7570196616343963 \tTime\t 61.06595492362976\n","Epoch\t 119 \tLoss\t 1.7373334108254848 \tTime\t 61.061851024627686\n","Epoch\t 120 \tLoss\t 1.7337906195567205 \tTime\t 61.12312841415405\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 121 \tLoss\t 1.7331855413241264 \tTime\t 61.369951009750366\n","Epoch\t 122 \tLoss\t 1.7483024542148298 \tTime\t 61.35363984107971\n","Epoch\t 123 \tLoss\t 1.7447441192773672 \tTime\t 61.05038666725159\n","Epoch\t 124 \tLoss\t 1.733243589523511 \tTime\t 61.2128746509552\n","Epoch\t 125 \tLoss\t 1.7215265420766976 \tTime\t 61.28373193740845\n","Epoch\t 126 \tLoss\t 1.7203724836691832 \tTime\t 61.10889196395874\n","Epoch\t 127 \tLoss\t 1.7220558661680956 \tTime\t 61.22570729255676\n","Epoch\t 128 \tLoss\t 1.7154307371530777 \tTime\t 61.33409929275513\n","Epoch\t 129 \tLoss\t 1.7500943104426065 \tTime\t 61.072038412094116\n","Epoch\t 130 \tLoss\t 1.7133382026965802 \tTime\t 61.08810758590698\n","Epoch\t 131 \tLoss\t 1.7286390634683462 \tTime\t 61.42731761932373\n","Epoch\t 132 \tLoss\t 1.7024340177193666 \tTime\t 61.11250901222229\n","Epoch\t 133 \tLoss\t 1.6945389662033472 \tTime\t 61.26357650756836\n","Epoch\t 134 \tLoss\t 1.706628617262229 \tTime\t 60.885544776916504\n","Epoch\t 135 \tLoss\t 1.6928773305354974 \tTime\t 61.20500111579895\n","Epoch\t 136 \tLoss\t 1.7163308559319912 \tTime\t 61.11485195159912\n","Epoch\t 137 \tLoss\t 1.6953670678994595 \tTime\t 61.09576177597046\n","Epoch\t 138 \tLoss\t 1.7093531877566606 \tTime\t 61.164865493774414\n","Epoch\t 139 \tLoss\t 1.6885704981975067 \tTime\t 61.25008225440979\n","Epoch\t 140 \tLoss\t 1.7000602887226985 \tTime\t 61.27047657966614\n","Epoch\t 141 \tLoss\t 1.7079531596257136 \tTime\t 61.02178335189819\n","Epoch\t 142 \tLoss\t 1.6935339481402667 \tTime\t 61.06564807891846\n","Epoch\t 143 \tLoss\t 1.6935405486669295 \tTime\t 61.44429564476013\n","Epoch\t 144 \tLoss\t 1.7099536339441934 \tTime\t 61.450828075408936\n","Epoch\t 145 \tLoss\t 1.6951257332777365 \tTime\t 61.51156735420227\n","Epoch\t 146 \tLoss\t 1.7104653969789163 \tTime\t 61.40094447135925\n","Epoch\t 147 \tLoss\t 1.6768597101553893 \tTime\t 61.61519241333008\n","Epoch\t 148 \tLoss\t 1.674734931725722 \tTime\t 61.734291553497314\n","Epoch\t 149 \tLoss\t 1.6745042379085835 \tTime\t 61.832435131073\n","Epoch\t 150 \tLoss\t 1.6907115905712813 \tTime\t 62.162328481674194\n","Epoch\t 151 \tLoss\t 1.6736684976479945 \tTime\t 62.10185480117798\n","Epoch\t 152 \tLoss\t 1.666499969898126 \tTime\t 62.609878063201904\n","Epoch\t 153 \tLoss\t 1.6718467663495968 \tTime\t 63.572343587875366\n","Epoch\t 154 \tLoss\t 1.6594643727327005 \tTime\t 62.58996796607971\n","Epoch\t 155 \tLoss\t 1.6621600444500262 \tTime\t 62.27130961418152\n","Epoch\t 156 \tLoss\t 1.6743034961896064 \tTime\t 62.68478751182556\n","Epoch\t 157 \tLoss\t 1.6588695862354377 \tTime\t 62.673829555511475\n","Epoch\t 158 \tLoss\t 1.6417780423775696 \tTime\t 63.21236991882324\n","Epoch\t 159 \tLoss\t 1.6658273935317993 \tTime\t 63.407917737960815\n","Epoch\t 160 \tLoss\t 1.6492179369315123 \tTime\t 63.3332257270813\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 161 \tLoss\t 1.6494744313068879 \tTime\t 63.706743478775024\n","Epoch\t 162 \tLoss\t 1.6674933274586996 \tTime\t 63.77061414718628\n","Epoch\t 163 \tLoss\t 1.6430323930887076 \tTime\t 64.45263838768005\n","Epoch\t 164 \tLoss\t 1.6475354940463336 \tTime\t 64.3793613910675\n","Epoch\t 165 \tLoss\t 1.6458793829648923 \tTime\t 65.0328299999237\n","Epoch\t 166 \tLoss\t 1.650868288675944 \tTime\t 64.7800874710083\n","Epoch\t 167 \tLoss\t 1.6474626431098351 \tTime\t 64.3146653175354\n","Epoch\t 168 \tLoss\t 1.6325923644579374 \tTime\t 64.20499110221863\n","Epoch\t 169 \tLoss\t 1.6505681520853288 \tTime\t 63.75740838050842\n","Epoch\t 170 \tLoss\t 1.6431949523779061 \tTime\t 63.75837755203247\n","Epoch\t 171 \tLoss\t 1.6417309877200004 \tTime\t 63.85912823677063\n","Epoch\t 172 \tLoss\t 1.6278493276009194 \tTime\t 63.843966007232666\n","Epoch\t 173 \tLoss\t 1.6185452993099505 \tTime\t 63.031909704208374\n","Epoch\t 174 \tLoss\t 1.6356041627052502 \tTime\t 62.91127943992615\n","Epoch\t 175 \tLoss\t 1.6392700562110314 \tTime\t 63.19546937942505\n","Epoch\t 176 \tLoss\t 1.6231166393328935 \tTime\t 63.08753752708435\n","Epoch\t 177 \tLoss\t 1.6247062132908747 \tTime\t 63.36319088935852\n","Epoch\t 178 \tLoss\t 1.620881158266312 \tTime\t 62.716771364212036\n","Epoch\t 179 \tLoss\t 1.6206200709709755 \tTime\t 62.730671644210815\n","Epoch\t 180 \tLoss\t 1.6206529941314305 \tTime\t 62.743579387664795\n","Epoch\t 181 \tLoss\t 1.6469202322837635 \tTime\t 63.325483322143555\n","Epoch\t 182 \tLoss\t 1.6134606330822676 \tTime\t 63.794246196746826\n","Epoch\t 183 \tLoss\t 1.6160560846328735 \tTime\t 62.9696409702301\n","Epoch\t 184 \tLoss\t 1.6169477658394056 \tTime\t 63.2354621887207\n","Epoch\t 185 \tLoss\t 1.6418780559148545 \tTime\t 63.86564230918884\n","Epoch\t 186 \tLoss\t 1.6328465015460283 \tTime\t 64.10710763931274\n","Epoch\t 187 \tLoss\t 1.6199234124941704 \tTime\t 64.34611749649048\n","Epoch\t 188 \tLoss\t 1.6164802037752593 \tTime\t 63.47553515434265\n","Epoch\t 189 \tLoss\t 1.6028919397256314 \tTime\t 64.0858633518219\n","Epoch\t 190 \tLoss\t 1.5969123748632579 \tTime\t 63.986504316329956\n","Epoch\t 191 \tLoss\t 1.6071425003883166 \tTime\t 63.307488679885864\n","Epoch\t 192 \tLoss\t 1.6185693526879334 \tTime\t 63.662994146347046\n","Epoch\t 193 \tLoss\t 1.6121924375876402 \tTime\t 63.93194341659546\n","Epoch\t 194 \tLoss\t 1.5876693646113078 \tTime\t 64.09988045692444\n","Epoch\t 195 \tLoss\t 1.5996065023617867 \tTime\t 64.63723659515381\n","Epoch\t 196 \tLoss\t 1.6023847506596491 \tTime\t 64.40847539901733\n","Epoch\t 197 \tLoss\t 1.609329897318131 \tTime\t 64.33457469940186\n","Epoch\t 198 \tLoss\t 1.5787556195870425 \tTime\t 63.597736835479736\n","Epoch\t 199 \tLoss\t 1.6100312850414178 \tTime\t 63.739527463912964\n","Epoch\t 200 \tLoss\t 1.600943985963479 \tTime\t 63.58316421508789\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 201 \tLoss\t 1.5925574773397202 \tTime\t 63.79933738708496\n","Epoch\t 202 \tLoss\t 1.5853143783716055 \tTime\t 63.26984786987305\n","Epoch\t 203 \tLoss\t 1.6025923606676933 \tTime\t 63.29283666610718\n","Epoch\t 204 \tLoss\t 1.5714475216009678 \tTime\t 63.20716404914856\n","Epoch\t 205 \tLoss\t 1.5764507226454907 \tTime\t 62.88308143615723\n","Epoch\t 206 \tLoss\t 1.5876348850054618 \tTime\t 63.42449903488159\n","Epoch\t 207 \tLoss\t 1.5838843321188902 \tTime\t 63.01815605163574\n","Epoch\t 208 \tLoss\t 1.5656177233426998 \tTime\t 63.32490563392639\n","Epoch\t 209 \tLoss\t 1.5888646064660488 \tTime\t 62.50861215591431\n","Epoch\t 210 \tLoss\t 1.5950489117549016 \tTime\t 62.5073139667511\n","Epoch\t 211 \tLoss\t 1.5671187877655028 \tTime\t 63.03204941749573\n","Epoch\t 212 \tLoss\t 1.5742869132604353 \tTime\t 63.578189849853516\n","Epoch\t 213 \tLoss\t 1.5757661788891524 \tTime\t 64.26833415031433\n","Epoch\t 214 \tLoss\t 1.5710875712908232 \tTime\t 64.40524792671204\n","Epoch\t 215 \tLoss\t 1.5693274027261979 \tTime\t 64.41275334358215\n","Epoch\t 216 \tLoss\t 1.5678743661978305 \tTime\t 64.32182884216309\n","Epoch\t 217 \tLoss\t 1.544136670919565 \tTime\t 63.878103733062744\n","Epoch\t 218 \tLoss\t 1.5806027351281582 \tTime\t 63.75273132324219\n","Epoch\t 219 \tLoss\t 1.5517470909998967 \tTime\t 64.29013013839722\n","Epoch\t 220 \tLoss\t 1.5675699741412432 \tTime\t 65.41632986068726\n","Epoch\t 221 \tLoss\t 1.565676517975636 \tTime\t 65.1000463962555\n","Epoch\t 222 \tLoss\t 1.5637774161803417 \tTime\t 64.71939420700073\n","Epoch\t 223 \tLoss\t 1.5695467588229057 \tTime\t 64.7373776435852\n","Epoch\t 224 \tLoss\t 1.586598028280796 \tTime\t 64.88131904602051\n","Epoch\t 225 \tLoss\t 1.5649263742642525 \tTime\t 65.5197594165802\n","Epoch\t 226 \tLoss\t 1.5514430003288464 \tTime\t 65.26299142837524\n","Epoch\t 227 \tLoss\t 1.5504527782782531 \tTime\t 64.69020819664001\n","Epoch\t 228 \tLoss\t 1.5554581024707892 \tTime\t 64.25829124450684\n","Epoch\t 229 \tLoss\t 1.5546753614376754 \tTime\t 63.86742353439331\n","Epoch\t 230 \tLoss\t 1.5512922800504245 \tTime\t 63.29503583908081\n","Epoch\t 231 \tLoss\t 1.5583086411158245 \tTime\t 63.38621807098389\n","Epoch\t 232 \tLoss\t 1.5662202688363882 \tTime\t 63.10178351402283\n","Epoch\t 233 \tLoss\t 1.543290358934647 \tTime\t 62.98084592819214\n","Epoch\t 234 \tLoss\t 1.537733852557647 \tTime\t 63.0673713684082\n","Epoch\t 235 \tLoss\t 1.5634543822361873 \tTime\t 62.87877297401428\n","Epoch\t 236 \tLoss\t 1.5597230672836304 \tTime\t 62.987255334854126\n","Epoch\t 237 \tLoss\t 1.536887156046354 \tTime\t 62.159810304641724\n","Epoch\t 238 \tLoss\t 1.5388209031178401 \tTime\t 62.66425013542175\n","Epoch\t 239 \tLoss\t 1.5346778154373169 \tTime\t 63.15553259849548\n","Epoch\t 240 \tLoss\t 1.546086988082299 \tTime\t 63.0837607383728\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 241 \tLoss\t 1.549957952132592 \tTime\t 64.47454953193665\n","Epoch\t 242 \tLoss\t 1.5414305607477823 \tTime\t 64.28766012191772\n","Epoch\t 243 \tLoss\t 1.5564314829997528 \tTime\t 64.0162501335144\n","Epoch\t 244 \tLoss\t 1.5319662601519854 \tTime\t 63.65212535858154\n","Epoch\t 245 \tLoss\t 1.5429141093523076 \tTime\t 63.89459848403931\n","Epoch\t 246 \tLoss\t 1.5425460161306919 \tTime\t 63.329766035079956\n","Epoch\t 247 \tLoss\t 1.5412775174165383 \tTime\t 63.93522000312805\n","Epoch\t 248 \tLoss\t 1.5361463925777337 \tTime\t 64.16338229179382\n","Epoch\t 249 \tLoss\t 1.5261354892681807 \tTime\t 63.81431770324707\n","Epoch\t 250 \tLoss\t 1.5422453024448493 \tTime\t 63.52633285522461\n","Epoch\t 251 \tLoss\t 1.5334798470521585 \tTime\t 63.427127838134766\n","Epoch\t 252 \tLoss\t 1.522338115863311 \tTime\t 64.38517642021179\n","Epoch\t 253 \tLoss\t 1.525645407040914 \tTime\t 64.10959911346436\n","Epoch\t 254 \tLoss\t 1.5147628979805188 \tTime\t 63.973841190338135\n","Epoch\t 255 \tLoss\t 1.5331059981615116 \tTime\t 64.12900829315186\n","Epoch\t 256 \tLoss\t 1.5424884435458062 \tTime\t 64.22885036468506\n","Epoch\t 257 \tLoss\t 1.531873946923476 \tTime\t 63.97422242164612\n","Epoch\t 258 \tLoss\t 1.5298894607103788 \tTime\t 64.03692650794983\n","Epoch\t 259 \tLoss\t 1.5389733467346582 \tTime\t 64.22627305984497\n","Epoch\t 260 \tLoss\t 1.5271827722207094 \tTime\t 64.38763880729675\n","Epoch\t 261 \tLoss\t 1.5273483166327844 \tTime\t 66.77825331687927\n","Epoch\t 262 \tLoss\t 1.521119053547199 \tTime\t 66.22711372375488\n","Epoch\t 263 \tLoss\t 1.5094102260393973 \tTime\t 64.45683884620667\n","Epoch\t 264 \tLoss\t 1.5302019932331183 \tTime\t 64.18742895126343\n","Epoch\t 265 \tLoss\t 1.527854465215634 \tTime\t 65.5577404499054\n","Epoch\t 266 \tLoss\t 1.5200007175787902 \tTime\t 63.362481355667114\n","Epoch\t 267 \tLoss\t 1.5084738719157684 \tTime\t 62.110599517822266\n","Epoch\t 268 \tLoss\t 1.512823251577524 \tTime\t 61.72451710700989\n","Epoch\t 269 \tLoss\t 1.5182710916568072 \tTime\t 61.502326011657715\n","Epoch\t 270 \tLoss\t 1.534100401095855 \tTime\t 61.9175660610199\n","Epoch\t 271 \tLoss\t 1.5253882793279794 \tTime\t 61.50869107246399\n","Epoch\t 272 \tLoss\t 1.5201112808325352 \tTime\t 61.66985273361206\n","Epoch\t 273 \tLoss\t 1.5194549181522468 \tTime\t 61.51021409034729\n","Epoch\t 274 \tLoss\t 1.5005112067247048 \tTime\t 61.59553027153015\n","Epoch\t 275 \tLoss\t 1.5263593618686382 \tTime\t 61.716428995132446\n","Epoch\t 276 \tLoss\t 1.5124732207029294 \tTime\t 61.56055760383606\n","Epoch\t 277 \tLoss\t 1.526045799255371 \tTime\t 61.571112394332886\n","Epoch\t 278 \tLoss\t 1.5222357725485778 \tTime\t 61.92585730552673\n","Epoch\t 279 \tLoss\t 1.528260985398904 \tTime\t 61.579978227615356\n","Epoch\t 280 \tLoss\t 1.5380388736724853 \tTime\t 62.08148956298828\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 281 \tLoss\t 1.5330371972842094 \tTime\t 61.72658395767212\n","Epoch\t 282 \tLoss\t 1.537317279057625 \tTime\t 61.68883395195007\n","Epoch\t 283 \tLoss\t 1.5233021901204036 \tTime\t 61.433021545410156\n","Epoch\t 284 \tLoss\t 1.5244453381269405 \tTime\t 61.612574100494385\n","Epoch\t 285 \tLoss\t 1.5243623702954023 \tTime\t 61.88457536697388\n","Epoch\t 286 \tLoss\t 1.5120560725529988 \tTime\t 61.43105673789978\n","Epoch\t 287 \tLoss\t 1.5175165390356993 \tTime\t 61.2767493724823\n","Epoch\t 288 \tLoss\t 1.5080340495476356 \tTime\t 61.52416205406189\n","Epoch\t 289 \tLoss\t 1.5103050776017017 \tTime\t 61.61465787887573\n","Epoch\t 290 \tLoss\t 1.5093766273596347 \tTime\t 61.882590532302856\n","Epoch\t 291 \tLoss\t 1.523945621955089 \tTime\t 61.518542528152466\n","Epoch\t 292 \tLoss\t 1.5042167535194984 \tTime\t 61.560922384262085\n","Epoch\t 293 \tLoss\t 1.50545445283254 \tTime\t 61.60360836982727\n","Epoch\t 294 \tLoss\t 1.530810633683816 \tTime\t 61.59240674972534\n","Epoch\t 295 \tLoss\t 1.5132813025743534 \tTime\t 61.82586050033569\n","Epoch\t 296 \tLoss\t 1.5209092513108864 \tTime\t 61.5232515335083\n","Epoch\t 297 \tLoss\t 1.5270105441411337 \tTime\t 61.67945384979248\n","Epoch\t 298 \tLoss\t 1.509088032062237 \tTime\t 61.630929946899414\n","Epoch\t 299 \tLoss\t 1.5188785235087077 \tTime\t 61.71907901763916\n","Epoch\t 300 \tLoss\t 1.5204968140675472 \tTime\t 61.975385904312134\n","Finished training. Train time was: 18773.143791913986\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 1 \tLoss\t 2.029850565470182 \tTime\t 8.30237627029419\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 2 \tLoss\t 1.6224471165583685 \tTime\t 8.248281002044678\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 3 \tLoss\t 1.4175495092685406 \tTime\t 8.30364465713501\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 4 \tLoss\t 1.3009648524797879 \tTime\t 8.282405138015747\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 5 \tLoss\t 1.2271841562711276 \tTime\t 8.275111675262451\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 6 \tLoss\t 1.1748361049554288 \tTime\t 8.311658382415771\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 7 \tLoss\t 1.1388543428518834 \tTime\t 8.257015466690063\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 8 \tLoss\t 1.1099277224296178 \tTime\t 8.282187938690186\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 9 \tLoss\t 1.0881443531085284 \tTime\t 8.266844749450684\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 10 \tLoss\t 1.0702062524282014 \tTime\t 8.283793926239014\n","Finished training. Train time was: 82.82899212837219\n","Accuracy : 64 %\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch\t 1 \tLoss\t 6.6106406749823154 \tTime\t 61.85085916519165\n","Epoch\t 2 \tLoss\t 6.120314874404516 \tTime\t 61.449371099472046\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1SR75sAMeN8n","executionInfo":{"status":"ok","timestamp":1601259307161,"user_tz":-540,"elapsed":649,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"b7d2db8b-f76c-4eb6-effb-6a0a449ceb27","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(os.path.isfile(\"gdrive/My Drive/simclr_{}_{}_epoch{}in{}.pt\".format(256, 0.07, 40, 300)))\n","print(os.path.isfile(\"gdrive/My Drive/simclr_new.pt\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["False\n","True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_UKFlSdlc1HL","executionInfo":{"status":"ok","timestamp":1601267425212,"user_tz":-540,"elapsed":7904009,"user":{"displayName":"­서준원 / 학생 / 컴퓨터공학부","photoUrl":"","userId":"17446851116920853979"}},"outputId":"929ee85e-f5fa-4535-ec32-1679721e1d50","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["n_epoch_list = [400]\n","\n","batch_loss =[]\n","temperature_loss =[]\n","epoch_loss =[]\n","\n","batch_acc =[]\n","temperature_acc =[]\n","epoch_acc =[]\n","\n","for n in n_epoch_list :\n","  net = SimCLRNet(26, 1, 10, 32)\n","  net.cuda()\n","  net.zero_grad()\n","  tl, ll, testl = make_loader(256)\n","  loss = train_param(net, tl, n_epoch=n)\n","  epoch_loss.append(loss)\n","  train_classifier(net, ll)\n","  acc = test_classifier(net, testl)\n","  epoch_acc.append((n, acc))\n","  save_model(net, \"simclr_epoch_{}.pt\".format(n))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 40\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 80\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 120\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 160\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 200\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 240\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","loaded 280\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch\t 281 \tLoss\t 1.5237562167338836 \tTime\t 67.56172299385071\n","Epoch\t 282 \tLoss\t 1.5223832961840507 \tTime\t 67.9060571193695\n","Epoch\t 283 \tLoss\t 1.5043408027062048 \tTime\t 67.62845969200134\n","Epoch\t 284 \tLoss\t 1.5353708065473117 \tTime\t 69.47301483154297\n","Epoch\t 285 \tLoss\t 1.5346112184035472 \tTime\t 67.88555121421814\n","Epoch\t 286 \tLoss\t 1.5212932831201798 \tTime\t 67.48591423034668\n","Epoch\t 287 \tLoss\t 1.5419591402396178 \tTime\t 67.65493893623352\n","Epoch\t 288 \tLoss\t 1.539744005447779 \tTime\t 67.16355490684509\n","Epoch\t 289 \tLoss\t 1.5445406681452043 \tTime\t 67.36112117767334\n","Epoch\t 290 \tLoss\t 1.5698883374532064 \tTime\t 67.50833058357239\n","Epoch\t 291 \tLoss\t 1.5511989801357955 \tTime\t 67.51949286460876\n","Epoch\t 292 \tLoss\t 1.5610361227622398 \tTime\t 67.50578308105469\n","Epoch\t 293 \tLoss\t 1.5599944787147717 \tTime\t 67.48384237289429\n","Epoch\t 294 \tLoss\t 1.5644306017802312 \tTime\t 67.5364100933075\n","Epoch\t 295 \tLoss\t 1.5762163785787728 \tTime\t 67.54439997673035\n","Epoch\t 296 \tLoss\t 1.594181099916116 \tTime\t 67.20052933692932\n","Epoch\t 297 \tLoss\t 1.5864878782859215 \tTime\t 67.10294508934021\n","Epoch\t 298 \tLoss\t 1.5967262720450377 \tTime\t 67.00351786613464\n","Epoch\t 299 \tLoss\t 1.5944966744153928 \tTime\t 67.34104347229004\n","Epoch\t 300 \tLoss\t 1.5972873504345233 \tTime\t 67.66621804237366\n","Epoch\t 301 \tLoss\t 1.6036562925729996 \tTime\t 68.20752263069153\n","Epoch\t 302 \tLoss\t 1.5886597089278391 \tTime\t 68.41743040084839\n","Epoch\t 303 \tLoss\t 1.6103743589841402 \tTime\t 67.84098482131958\n","Epoch\t 304 \tLoss\t 1.6264523341105535 \tTime\t 66.66321396827698\n","Epoch\t 305 \tLoss\t 1.6237755922170787 \tTime\t 65.21247839927673\n","Epoch\t 306 \tLoss\t 1.6077275037765504 \tTime\t 65.94034314155579\n","Epoch\t 307 \tLoss\t 1.6160729188185472 \tTime\t 66.4089949131012\n","Epoch\t 308 \tLoss\t 1.6262215693791708 \tTime\t 65.91028165817261\n","Epoch\t 309 \tLoss\t 1.6448267068618383 \tTime\t 67.22157549858093\n","Epoch\t 310 \tLoss\t 1.6280602485705644 \tTime\t 65.96110248565674\n","Epoch\t 311 \tLoss\t 1.6188653138967661 \tTime\t 66.43164706230164\n","Epoch\t 312 \tLoss\t 1.6451770794697298 \tTime\t 66.89888453483582\n","Epoch\t 313 \tLoss\t 1.6562913882426726 \tTime\t 66.8540415763855\n","Epoch\t 314 \tLoss\t 1.6598347627199612 \tTime\t 67.35029149055481\n","Epoch\t 315 \tLoss\t 1.6437727683629746 \tTime\t 67.13466691970825\n","Epoch\t 316 \tLoss\t 1.66166869921562 \tTime\t 66.95046734809875\n","Epoch\t 317 \tLoss\t 1.6578162144391964 \tTime\t 67.42098474502563\n","Epoch\t 318 \tLoss\t 1.6817856317911393 \tTime\t 67.26303267478943\n","Epoch\t 319 \tLoss\t 1.6717226419693385 \tTime\t 67.43202614784241\n","Epoch\t 320 \tLoss\t 1.6756854491356092 \tTime\t 67.00402998924255\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 321 \tLoss\t 1.6705405828280326 \tTime\t 67.40703749656677\n","Epoch\t 322 \tLoss\t 1.6752415962708302 \tTime\t 67.10406613349915\n","Epoch\t 323 \tLoss\t 1.6743716282722279 \tTime\t 67.19386339187622\n","Epoch\t 324 \tLoss\t 1.6702231315466074 \tTime\t 66.97608709335327\n","Epoch\t 325 \tLoss\t 1.6549740681281457 \tTime\t 66.92499828338623\n","Epoch\t 326 \tLoss\t 1.654048153070303 \tTime\t 66.66854810714722\n","Epoch\t 327 \tLoss\t 1.6616563613598163 \tTime\t 66.44685411453247\n","Epoch\t 328 \tLoss\t 1.6605095838889097 \tTime\t 66.85036158561707\n","Epoch\t 329 \tLoss\t 1.6666306593479254 \tTime\t 67.74177813529968\n","Epoch\t 330 \tLoss\t 1.6565114791576678 \tTime\t 67.92543339729309\n","Epoch\t 331 \tLoss\t 1.657364441186954 \tTime\t 67.82764744758606\n","Epoch\t 332 \tLoss\t 1.6448818463545578 \tTime\t 67.85136651992798\n","Epoch\t 333 \tLoss\t 1.6615122507780027 \tTime\t 67.05975580215454\n","Epoch\t 334 \tLoss\t 1.638044173289568 \tTime\t 66.88503122329712\n","Epoch\t 335 \tLoss\t 1.6482457552200709 \tTime\t 65.35374736785889\n","Epoch\t 336 \tLoss\t 1.6461559534072876 \tTime\t 65.93617129325867\n","Epoch\t 337 \tLoss\t 1.6427362753794743 \tTime\t 68.11449003219604\n","Epoch\t 338 \tLoss\t 1.646443389623593 \tTime\t 64.43060088157654\n","Epoch\t 339 \tLoss\t 1.6299819720097077 \tTime\t 63.21625852584839\n","Epoch\t 340 \tLoss\t 1.6473186321747608 \tTime\t 63.10442233085632\n","Epoch\t 341 \tLoss\t 1.6537246991426517 \tTime\t 63.78670787811279\n","Epoch\t 342 \tLoss\t 1.6345720395063743 \tTime\t 64.27998471260071\n","Epoch\t 343 \tLoss\t 1.6405827436691676 \tTime\t 64.30644798278809\n","Epoch\t 344 \tLoss\t 1.625097847596193 \tTime\t 64.48796200752258\n","Epoch\t 345 \tLoss\t 1.6224132403349265 \tTime\t 64.71559500694275\n","Epoch\t 346 \tLoss\t 1.6343775847019293 \tTime\t 65.34168553352356\n","Epoch\t 347 \tLoss\t 1.6387793192496667 \tTime\t 65.49168729782104\n","Epoch\t 348 \tLoss\t 1.6470226489580595 \tTime\t 65.37380933761597\n","Epoch\t 349 \tLoss\t 1.6318018314165947 \tTime\t 66.29200315475464\n","Epoch\t 350 \tLoss\t 1.6390007752638596 \tTime\t 69.02196455001831\n","Epoch\t 351 \tLoss\t 1.6140822202731402 \tTime\t 67.33508801460266\n","Epoch\t 352 \tLoss\t 1.6274236507904836 \tTime\t 66.64516568183899\n","Epoch\t 353 \tLoss\t 1.6226062193894997 \tTime\t 66.55122542381287\n","Epoch\t 354 \tLoss\t 1.6125474428519224 \tTime\t 66.6607174873352\n","Epoch\t 355 \tLoss\t 1.607486089070638 \tTime\t 67.19764828681946\n","Epoch\t 356 \tLoss\t 1.6254692095976608 \tTime\t 68.11523365974426\n","Epoch\t 357 \tLoss\t 1.6130231710580678 \tTime\t 67.6517083644867\n","Epoch\t 358 \tLoss\t 1.6334316761065752 \tTime\t 67.25457620620728\n","Epoch\t 359 \tLoss\t 1.617551310857137 \tTime\t 67.60948610305786\n","Epoch\t 360 \tLoss\t 1.6127738940410126 \tTime\t 69.80960488319397\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 361 \tLoss\t 1.6083531232980581 \tTime\t 67.75008487701416\n","Epoch\t 362 \tLoss\t 1.6044196086052136 \tTime\t 65.87170338630676\n","Epoch\t 363 \tLoss\t 1.6056764938892463 \tTime\t 63.74572277069092\n","Epoch\t 364 \tLoss\t 1.609727025643373 \tTime\t 63.26177406311035\n","Epoch\t 365 \tLoss\t 1.6078997110709166 \tTime\t 65.14530205726624\n","Epoch\t 366 \tLoss\t 1.597107649460817 \tTime\t 62.61906385421753\n","Epoch\t 367 \tLoss\t 1.588542092152131 \tTime\t 62.036248445510864\n","Epoch\t 368 \tLoss\t 1.58031820333921 \tTime\t 61.51442527770996\n","Epoch\t 369 \tLoss\t 1.5976202041674883 \tTime\t 61.59179162979126\n","Epoch\t 370 \tLoss\t 1.5967342615127564 \tTime\t 61.37758183479309\n","Epoch\t 371 \tLoss\t 1.6007983623406825 \tTime\t 60.943376779556274\n","Epoch\t 372 \tLoss\t 1.596521100631127 \tTime\t 61.2686767578125\n","Epoch\t 373 \tLoss\t 1.5901006295130804 \tTime\t 60.973628282547\n","Epoch\t 374 \tLoss\t 1.5830671548843385 \tTime\t 61.079787492752075\n","Epoch\t 375 \tLoss\t 1.6016644911888318 \tTime\t 60.80355477333069\n","Epoch\t 376 \tLoss\t 1.5948866208394368 \tTime\t 61.57189726829529\n","Epoch\t 377 \tLoss\t 1.604367758677556 \tTime\t 60.94631838798523\n","Epoch\t 378 \tLoss\t 1.5918391814598671 \tTime\t 60.86111044883728\n","Epoch\t 379 \tLoss\t 1.6062673642085148 \tTime\t 62.88778519630432\n","Epoch\t 380 \tLoss\t 1.591598864702078 \tTime\t 61.69953227043152\n","Epoch\t 381 \tLoss\t 1.5944095128621811 \tTime\t 61.16888785362244\n","Epoch\t 382 \tLoss\t 1.595531849983411 \tTime\t 61.0810604095459\n","Epoch\t 383 \tLoss\t 1.5787969460854163 \tTime\t 61.18803930282593\n","Epoch\t 384 \tLoss\t 1.5863425798905202 \tTime\t 60.990466594696045\n","Epoch\t 385 \tLoss\t 1.590431184035081 \tTime\t 60.92186760902405\n","Epoch\t 386 \tLoss\t 1.5883352750386948 \tTime\t 61.132853984832764\n","Epoch\t 387 \tLoss\t 1.5911818785545153 \tTime\t 61.20096445083618\n","Epoch\t 388 \tLoss\t 1.5970782078229464 \tTime\t 60.90113067626953\n","Epoch\t 389 \tLoss\t 1.5803912175007355 \tTime\t 61.083354234695435\n","Epoch\t 390 \tLoss\t 1.567535791030297 \tTime\t 61.14259910583496\n","Epoch\t 391 \tLoss\t 1.5679759557430561 \tTime\t 61.11433720588684\n","Epoch\t 392 \tLoss\t 1.5941543719707392 \tTime\t 60.701942920684814\n","Epoch\t 393 \tLoss\t 1.5957453935574262 \tTime\t 60.737224102020264\n","Epoch\t 394 \tLoss\t 1.5604128097876524 \tTime\t 60.53668165206909\n","Epoch\t 395 \tLoss\t 1.558970675101647 \tTime\t 60.59624528884888\n","Epoch\t 396 \tLoss\t 1.5640235191736467 \tTime\t 60.64073944091797\n","Epoch\t 397 \tLoss\t 1.5660724053016075 \tTime\t 60.69511818885803\n","Epoch\t 398 \tLoss\t 1.5764728711201594 \tTime\t 60.59148383140564\n","Epoch\t 399 \tLoss\t 1.5741060220278227 \tTime\t 60.69718098640442\n","Epoch\t 400 \tLoss\t 1.556201560069353 \tTime\t 60.64142680168152\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Finished training. Train time was: 7816.876214504242\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 1 \tLoss\t 1.9966736139395298 \tTime\t 8.541545629501343\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 2 \tLoss\t 1.563931024991549 \tTime\t 8.203174352645874\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 3 \tLoss\t 1.3624869585037231 \tTime\t 8.227479457855225\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 4 \tLoss\t 1.254024135760772 \tTime\t 8.23048710823059\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 5 \tLoss\t 1.1860764326193394 \tTime\t 8.191762685775757\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 6 \tLoss\t 1.1394636545425807 \tTime\t 8.182939529418945\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 7 \tLoss\t 1.1052930672963461 \tTime\t 8.167297840118408\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 8 \tLoss\t 1.080558681488037 \tTime\t 8.20409893989563\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 9 \tLoss\t 1.0601865508617498 \tTime\t 8.175497770309448\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Epoch\t 10 \tLoss\t 1.0451578403130555 \tTime\t 8.192955255508423\n","Finished training. Train time was: 82.33093237876892\n","Accuracy : 65 %\n","Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]}]}